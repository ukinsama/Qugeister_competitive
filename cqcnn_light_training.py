#!/usr/bin/env python3
"""
CQCNNè»½é‡å­¦ç¿’ç‰ˆ - å­¦ç¿’ã«ã‚ˆã‚‹å‹ç‡å‘ä¸Šãƒ†ã‚¹ãƒˆ
æœ€å°é™ã®å­¦ç¿’ã§åŠ¹æœã‚’ç¢ºèª
"""

import sys
import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from typing import Dict, Tuple, List, Optional
import random
import time
import json

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src', 'qugeister_competitive')
sys.path.insert(0, src_path)
sys.path.insert(0, current_dir)

print("ğŸ“‚ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ä¸­...")

# å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
with open(os.path.join(src_path, 'game_engine.py'), 'r') as f:
    exec(f.read())

with open(os.path.join(src_path, 'ai_base.py'), 'r') as f:
    code = f.read().replace('from .game_engine', '# from .game_engine')
    exec(code)

from separated_cqcnn_qmap import (
    CQCNNPieceEstimator,
    QValueMapGenerator,
    IntegratedCQCNNSystem
)

print("âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\n")


# ================================================================================
# è»½é‡å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
# ================================================================================

class LightweightTrainer:
    """è»½é‡å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, n_qubits: int = 4, n_layers: int = 2):
        # è»½é‡CQCNNã‚·ã‚¹ãƒ†ãƒ 
        self.system = IntegratedCQCNNSystem(n_qubits=n_qubits, n_layers=n_layers)
        self.optimizer = optim.Adam(self.system.estimator.parameters(), lr=0.01)
        self.criterion = nn.BCELoss()  # Binary Cross Entropy
        
        self.training_stats = {
            'before_accuracy': 0,
            'after_accuracy': 0,
            'loss_history': []
        }
    
    def generate_simple_training_data(self, num_games: int = 10):
        """ç°¡æ˜“å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­ ({num_games}ã‚²ãƒ¼ãƒ )...")
        data = []
        
        for game_idx in range(num_games):
            game = GeisterGame()
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«20æ‰‹é€²ã‚ã‚‹
            for _ in range(20):
                legal_moves = game.get_legal_moves(game.current_player)
                if not legal_moves or game.game_over:
                    break
                move = random.choice(legal_moves)
                game.make_move(move[0], move[1])
            
            # ç¾åœ¨ã®ç›¤é¢ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            if not game.game_over:
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®è¦–ç‚¹
                board_tensor = self._create_board_tensor(game.board, "A")
                
                # æ•µé§’ï¼ˆãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bï¼‰ã®æƒ…å ±
                for pos, piece_type in game.player_b_pieces.items():
                    data.append({
                        'board_tensor': board_tensor,
                        'position': pos,
                        'is_good': piece_type == "good",
                        'player': "A"
                    })
            
            print(f"  ã‚²ãƒ¼ãƒ  {game_idx + 1}/{num_games} å®Œäº†")
        
        print(f"âœ… {len(data)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ\n")
        return data
    
    def _create_board_tensor(self, board: np.ndarray, player: str) -> torch.Tensor:
        """ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›"""
        tensor = torch.zeros(1, 3, 6, 6)
        player_val = 1 if player == "A" else -1
        enemy_val = -player_val
        
        tensor[0, 0] = torch.from_numpy((board == player_val).astype(np.float32))
        tensor[0, 1] = torch.from_numpy((board == enemy_val).astype(np.float32))
        tensor[0, 2] = torch.from_numpy((board == 0).astype(np.float32))
        
        return tensor
    
    def train_quick(self, training_data: List[Dict], epochs: int = 10):
        """è»½é‡å­¦ç¿’å®Ÿè¡Œ"""
        print(f"ğŸ“ è»½é‡å­¦ç¿’é–‹å§‹ (ã‚¨ãƒãƒƒã‚¯æ•°: {epochs})")
        print("-" * 40)
        
        if not training_data:
            print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return
        
        # å­¦ç¿’å‰ã®ç²¾åº¦æ¸¬å®š
        before_correct = 0
        for data_point in training_data[:10]:  # æœ€åˆã®10å€‹ã§ãƒ†ã‚¹ãƒˆ
            pred = self._predict_piece_type(data_point['board_tensor'], data_point['position'])
            if (pred > 0.5) == data_point['is_good']:
                before_correct += 1
        self.training_stats['before_accuracy'] = before_correct / min(10, len(training_data))
        
        # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(epochs):
            epoch_loss = 0
            correct = 0
            total = 0
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            random.shuffle(training_data)
            
            for data_point in training_data:
                # äºˆæ¸¬
                self.optimizer.zero_grad()
                
                # CQCNNã§æ¨å®š
                estimations = self.system.estimator(
                    data_point['board_tensor'],
                    [data_point['position']]
                )
                
                if estimations:
                    est = estimations[0]
                    pred_good = torch.tensor([est.good_probability], requires_grad=True)
                    
                    # çœŸã®ãƒ©ãƒ™ãƒ«
                    target = torch.tensor([1.0 if data_point['is_good'] else 0.0])
                    
                    # æå¤±è¨ˆç®—
                    loss = self.criterion(pred_good, target)
                    loss.backward()
                    self.optimizer.step()
                    
                    epoch_loss += loss.item()
                    
                    # ç²¾åº¦è¨ˆç®—
                    if (pred_good.item() > 0.5) == data_point['is_good']:
                        correct += 1
                    total += 1
            
            # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆ
            if total > 0:
                accuracy = correct / total
                avg_loss = epoch_loss / total
                self.training_stats['loss_history'].append(avg_loss)
                
                if (epoch + 1) % 2 == 0:
                    print(f"  Epoch {epoch+1:2d}/{epochs} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2%}")
        
        # å­¦ç¿’å¾Œã®ç²¾åº¦æ¸¬å®š
        after_correct = 0
        for data_point in training_data[:10]:
            pred = self._predict_piece_type(data_point['board_tensor'], data_point['position'])
            if (pred > 0.5) == data_point['is_good']:
                after_correct += 1
        self.training_stats['after_accuracy'] = after_correct / min(10, len(training_data))
        
        print("\nâœ… å­¦ç¿’å®Œäº†ï¼")
        print(f"  å­¦ç¿’å‰ç²¾åº¦: {self.training_stats['before_accuracy']:.1%}")
        print(f"  å­¦ç¿’å¾Œç²¾åº¦: {self.training_stats['after_accuracy']:.1%}")
        improvement = self.training_stats['after_accuracy'] - self.training_stats['before_accuracy']
        print(f"  æ”¹å–„å¹…: {improvement:+.1%}\n")
    
    def _predict_piece_type(self, board_tensor: torch.Tensor, position: Tuple) -> float:
        """é§’ã‚¿ã‚¤ãƒ—ã‚’äºˆæ¸¬"""
        with torch.no_grad():
            estimations = self.system.estimator(board_tensor, [position])
            if estimations:
                return estimations[0].good_probability
        return 0.5


# ================================================================================
# å­¦ç¿’æ¸ˆã¿CQCNN AI
# ================================================================================

class TrainedCQCNNAI(BaseAI):
    """å­¦ç¿’æ¸ˆã¿CQCNN AI"""
    
    def __init__(self, player_id: str, system: IntegratedCQCNNSystem, name: str = "TrainedCQCNN"):
        super().__init__(name, player_id)
        self.system = system
        self.exploration_rate = 0.1  # å­¦ç¿’å¾Œã¯æ¢ç´¢ç‡ã‚’ä¸‹ã’ã‚‹
    
    def get_move(self, game_state: GameState, legal_moves: List) -> Optional[Tuple]:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§æ‰‹ã‚’é¸æŠ"""
        if not legal_moves:
            return None
        
        # 10%ã®ç¢ºç‡ã§ãƒ©ãƒ³ãƒ€ãƒ 
        if random.random() < self.exploration_rate:
            return random.choice(legal_moves)
        
        # Qå€¤ãƒãƒƒãƒ—ã‚’ä½¿ã£ãŸè©•ä¾¡
        try:
            # ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            game_dict = {
                'board': game_state.board.tolist(),
                'current_player': self.player_id,
                'turn': game_state.turn
            }
            
            # è‡ªåˆ†ã®é§’æƒ…å ±
            my_pieces = game_state.player_a_pieces if self.player_id == "A" else game_state.player_b_pieces
            
            # é§’æ¨å®šã¨Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ
            estimation_data, q_map = self.system.process_game_state(game_dict, my_pieces)
            
            # æœ€é©æ‰‹é¸æŠ
            best_move = None
            best_score = -float('inf')
            
            for move in legal_moves:
                from_pos, to_pos = move
                
                # åŸºæœ¬ã‚¹ã‚³ã‚¢
                score = self._evaluate_move(move, game_state)
                
                # Qå€¤ã‚‚è€ƒæ…®ï¼ˆå¯èƒ½ãªã‚‰ï¼‰
                try:
                    dx = to_pos[0] - from_pos[0]
                    dy = to_pos[1] - from_pos[1]
                    
                    if dy == -1 and dx == 0:    dir_idx = 0
                    elif dx == 1 and dy == 0:   dir_idx = 1
                    elif dy == 1 and dx == 0:   dir_idx = 2
                    elif dx == -1 and dy == 0:  dir_idx = 3
                    else: dir_idx = -1
                    
                    if dir_idx >= 0:
                        q_value = q_map[from_pos[1], from_pos[0], dir_idx]
                        score += q_value * 0.1  # Qå€¤ã®å½±éŸ¿ã‚’èª¿æ•´
                except:
                    pass
                
                if score > best_score:
                    best_score = score
                    best_move = move
            
            return best_move if best_move else random.choice(legal_moves)
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç°¡æ˜“è©•ä¾¡
            return self._get_simple_move(game_state, legal_moves)
    
    def _evaluate_move(self, move: Tuple, game_state: GameState) -> float:
        """æ‰‹ã®è©•ä¾¡"""
        from_pos, to_pos = move
        score = 0.0
        
        # å‰é€²ãƒœãƒ¼ãƒŠã‚¹
        if self.player_id == "A":
            score += (to_pos[1] - from_pos[1]) * 3.0
        else:
            score += (from_pos[1] - to_pos[1]) * 3.0
        
        # ä¸­å¤®åˆ¶å¾¡
        center_dist = abs(to_pos[0] - 2.5)
        score += (2.5 - center_dist) * 1.0
        
        # é§’å–ã‚Š
        opponent_pieces = game_state.player_b_pieces if self.player_id == "A" else game_state.player_a_pieces
        if to_pos in opponent_pieces:
            score += 8.0
        
        return score
    
    def _get_simple_move(self, game_state: GameState, legal_moves: List) -> Tuple:
        """ç°¡æ˜“æ‰‹é¸æŠ"""
        scores = []
        for move in legal_moves:
            score = self._evaluate_move(move, game_state)
            scores.append((move, score))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[0][0] if scores else random.choice(legal_moves)


# ================================================================================
# æ¯”è¼ƒå®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ 
# ================================================================================

def run_comparison_tournament(ai_list: List[BaseAI], games_per_pair: int = 5):
    """AIåŒå£«ã®ç·å½“ãŸã‚Šæˆ¦"""
    print("\nğŸ† æ¯”è¼ƒãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆ")
    print("=" * 60)
    
    results = {}
    
    for ai in ai_list:
        results[ai.name] = {'wins': 0, 'games': 0}
    
    # ç·å½“ãŸã‚Šæˆ¦
    for i, ai1 in enumerate(ai_list):
        for j, ai2 in enumerate(ai_list):
            if i >= j:  # è‡ªåˆ†è‡ªèº«ã¨ã®å¯¾æˆ¦ã¨é‡è¤‡ã‚’é¿ã‘ã‚‹
                continue
            
            print(f"\n{ai1.name} vs {ai2.name} ({games_per_pair}ã‚²ãƒ¼ãƒ )")
            
            for game_num in range(games_per_pair):
                game = GeisterGame()
                
                # å…ˆæ‰‹å¾Œæ‰‹ã‚’äº¤ä»£
                if game_num % 2 == 0:
                    player_a, player_b = ai1, ai2
                    ai1.player_id, ai2.player_id = "A", "B"
                else:
                    player_a, player_b = ai2, ai1
                    ai1.player_id, ai2.player_id = "B", "A"
                
                # ã‚²ãƒ¼ãƒ å®Ÿè¡Œ
                max_turns = 100
                for turn in range(max_turns):
                    current_ai = player_a if game.current_player == "A" else player_b
                    legal_moves = game.get_legal_moves(game.current_player)
                    
                    if not legal_moves or game.game_over:
                        break
                    
                    game_state = game.get_game_state(game.current_player)
                    move = current_ai.get_move(game_state, legal_moves)
                    
                    if move:
                        game.make_move(move[0], move[1])
                
                # çµæœè¨˜éŒ²
                if game.winner == "A":
                    winner = player_a
                elif game.winner == "B":
                    winner = player_b
                else:
                    winner = None
                
                if winner:
                    results[winner.name]['wins'] += 1
                
                results[ai1.name]['games'] += 1
                results[ai2.name]['games'] += 1
                
                # çµæœè¡¨ç¤º
                result_str = winner.name if winner else "Draw"
                print(f"  Game {game_num + 1}: {result_str}")
    
    # æœ€çµ‚çµæœè¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€çµ‚çµæœ")
    print("-" * 40)
    
    # å‹ç‡ã§ã‚½ãƒ¼ãƒˆ
    sorted_results = sorted(results.items(), 
                          key=lambda x: x[1]['wins'] / max(x[1]['games'], 1), 
                          reverse=True)
    
    for name, stats in sorted_results:
        win_rate = stats['wins'] / max(stats['games'], 1) * 100
        print(f"{name:15s}: {stats['wins']:2d}/{stats['games']:2d} å‹ (å‹ç‡: {win_rate:.0f}%)")
    
    return results


# ================================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ================================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ CQCNNè»½é‡å­¦ç¿’ç‰ˆ - å‹ç‡å‘ä¸Šãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # Phase 1: å­¦ç¿’å‰ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
    print("\n[Phase 1] å­¦ç¿’å‰ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š")
    print("-" * 40)
    
    # æœªå­¦ç¿’CQCNN
    untrained_system = IntegratedCQCNNSystem(n_qubits=4, n_layers=2)
    untrained_ai = TrainedCQCNNAI("A", untrained_system, "CQCNN_æœªå­¦ç¿’")
    
    # å¯¾æˆ¦ç›¸æ‰‹
    random_ai = RandomAI("B")
    simple_ai = SimpleAI("B")
    
    print("ğŸ“Š å­¦ç¿’å‰ã®æ€§èƒ½æ¸¬å®šï¼ˆå„5ã‚²ãƒ¼ãƒ ï¼‰")
    
    # å­¦ç¿’å‰ã®ãƒ†ã‚¹ãƒˆ
    untrained_wins = 0
    for opponent in [random_ai, simple_ai]:
        wins = 0
        for i in range(5):
            game = GeisterGame()
            
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è¨­å®š
            if i % 2 == 0:
                untrained_ai.player_id = "A"
                opponent.player_id = "B"
                player_a, player_b = untrained_ai, opponent
            else:
                untrained_ai.player_id = "B"
                opponent.player_id = "A"
                player_a, player_b = opponent, untrained_ai
            
            # ã‚²ãƒ¼ãƒ å®Ÿè¡Œï¼ˆç°¡ç•¥ç‰ˆï¼‰
            for _ in range(100):
                if game.game_over:
                    break
                current = player_a if game.current_player == "A" else player_b
                moves = game.get_legal_moves(game.current_player)
                if moves:
                    move = current.get_move(game.get_game_state(game.current_player), moves)
                    if move:
                        game.make_move(move[0], move[1])
            
            if (i % 2 == 0 and game.winner == "A") or (i % 2 == 1 and game.winner == "B"):
                wins += 1
                untrained_wins += 1
        
        print(f"  vs {opponent.name}: {wins}/5 å‹")
    
    baseline_winrate = untrained_wins / 10 * 100
    print(f"\nğŸ“ˆ å­¦ç¿’å‰å‹ç‡: {baseline_winrate:.0f}%")
    
    # Phase 2: è»½é‡å­¦ç¿’
    print("\n[Phase 2] è»½é‡å­¦ç¿’å®Ÿè¡Œ")
    print("-" * 40)
    
    trainer = LightweightTrainer(n_qubits=4, n_layers=2)
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    training_data = trainer.generate_simple_training_data(num_games=15)
    
    # å­¦ç¿’å®Ÿè¡Œ
    trainer.train_quick(training_data, epochs=10)
    
    # Phase 3: å­¦ç¿’å¾Œãƒ†ã‚¹ãƒˆ
    print("\n[Phase 3] å­¦ç¿’å¾Œæ€§èƒ½æ¸¬å®š")
    print("-" * 40)
    
    # å­¦ç¿’æ¸ˆã¿AI
    trained_ai = TrainedCQCNNAI("A", trainer.system, "CQCNN_å­¦ç¿’æ¸ˆ")
    
    print("ğŸ“Š å­¦ç¿’å¾Œã®æ€§èƒ½æ¸¬å®šï¼ˆå„5ã‚²ãƒ¼ãƒ ï¼‰")
    
    # å­¦ç¿’å¾Œã®ãƒ†ã‚¹ãƒˆ
    trained_wins = 0
    for opponent in [random_ai, simple_ai]:
        wins = 0
        for i in range(5):
            game = GeisterGame()
            
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è¨­å®š
            if i % 2 == 0:
                trained_ai.player_id = "A"
                opponent.player_id = "B"
                player_a, player_b = trained_ai, opponent
            else:
                trained_ai.player_id = "B"
                opponent.player_id = "A"
                player_a, player_b = opponent, trained_ai
            
            # ã‚²ãƒ¼ãƒ å®Ÿè¡Œ
            for _ in range(100):
                if game.game_over:
                    break
                current = player_a if game.current_player == "A" else player_b
                moves = game.get_legal_moves(game.current_player)
                if moves:
                    move = current.get_move(game.get_game_state(game.current_player), moves)
                    if move:
                        game.make_move(move[0], move[1])
            
            if (i % 2 == 0 and game.winner == "A") or (i % 2 == 1 and game.winner == "B"):
                wins += 1
                trained_wins += 1
        
        print(f"  vs {opponent.name}: {wins}/5 å‹")
    
    trained_winrate = trained_wins / 10 * 100
    print(f"\nğŸ“ˆ å­¦ç¿’å¾Œå‹ç‡: {trained_winrate:.0f}%")
    
    # Phase 4: ç·åˆæ¯”è¼ƒ
    print("\n[Phase 4] ç·åˆæ¯”è¼ƒãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆ")
    print("-" * 40)
    
    # å…¨AIå‚åŠ ã®ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆ
    all_ais = [
        untrained_ai,
        trained_ai,
        random_ai,
        simple_ai,
        AggressiveAI("A")
    ]
    
    tournament_results = run_comparison_tournament(all_ais, games_per_pair=3)
    
    # Phase 5: çµæœåˆ†æ
    print("\n[Phase 5] çµæœåˆ†æ")
    print("=" * 60)
    
    print("\nğŸ“Š å­¦ç¿’åŠ¹æœåˆ†æ:")
    print(f"  å­¦ç¿’å‰å‹ç‡: {baseline_winrate:.0f}%")
    print(f"  å­¦ç¿’å¾Œå‹ç‡: {trained_winrate:.0f}%")
    improvement = trained_winrate - baseline_winrate
    print(f"  æ”¹å–„å¹…: {improvement:+.0f}%")
    
    if improvement > 0:
        print(f"\nâœ¨ å­¦ç¿’æˆåŠŸï¼")
        print(f"  {improvement:.0f}%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆ")
    elif improvement == 0:
        print(f"\nğŸ“ˆ å¤‰åŒ–ãªã—")
        print(f"  ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
    else:
        print(f"\nğŸ”„ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒå¿…è¦")
        print(f"  å­¦ç¿’æ–¹æ³•ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™")
    
    print("\nğŸ’¡ æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ:")
    if trainer.training_stats['after_accuracy'] > 0.6:
        print("  âœ… é§’æ¨å®šç²¾åº¦ã¯è‰¯å¥½")
    else:
        print("  ğŸ“ˆ é§’æ¨å®šç²¾åº¦ã®å‘ä¸ŠãŒå¿…è¦")
    
    print("  - ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿")
    print("  - ã‚¨ãƒãƒƒã‚¯æ•°ã®å¢—åŠ ")
    print("  - å­¦ç¿’ç‡ã®èª¿æ•´")
    
    print("\nâœ… å®Ÿé¨“å®Œäº†ï¼")


if __name__ == "__main__":
    try:
        start_time = time.time()
        main()
        elapsed = time.time() - start_time
        print(f"\nâ±ï¸ å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
    except KeyboardInterrupt:
        print("\nâš ï¸ å®Ÿè¡Œä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
