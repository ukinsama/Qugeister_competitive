#!/usr/bin/env python3
"""
å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»å¾©å…ƒæ¤œè¨¼ãƒ„ãƒ¼ãƒ«
.pthãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰AIã‚’å®Œå…¨å†æ§‹æˆã§ãã‚‹ã‹ãƒ†ã‚¹ãƒˆ
"""

import os
import torch
import numpy as np
from typing import Dict, Any, List, Tuple
import json
from datetime import datetime

class ModelPersistenceVerifier:
    """ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»å¾©å…ƒã®æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.test_results = {}
        self.available_models = []
        
    def find_saved_models(self) -> List[str]:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        print("ğŸ” ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢")
        print("=" * 50)
        
        model_files = []
        for file in os.listdir('.'):
            if file.endswith('.pth'):
                model_files.append(file)
                print(f"  âœ… ç™ºè¦‹: {file}")
                
        self.available_models = model_files
        print(f"\nğŸ“Š ç·æ•°: {len(model_files)} å€‹ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«")
        return model_files
    
    def analyze_model_structure(self, model_path: str) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®åˆ†æ"""
        print(f"\nğŸ”¬ ãƒ¢ãƒ‡ãƒ«æ§‹é€ åˆ†æ: {model_path}")
        print("-" * 50)
        
        try:
            # .pthãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            checkpoint = torch.load(model_path, map_location='cpu')
            
            analysis = {
                'file_path': model_path,
                'file_size': os.path.getsize(model_path),
                'keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'not_dict',
                'model_state_dict_available': False,
                'optimizer_state_dict_available': False,
                'training_metadata': {},
                'model_parameters': {},
                'reconstruction_possible': False
            }
            
            print(f"  ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {analysis['file_size']:,} bytes")
            
            if isinstance(checkpoint, dict):
                print(f"  ğŸ—‚ï¸ ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼: {len(checkpoint.keys())} å€‹")
                for key in checkpoint.keys():
                    print(f"    - {key}: {type(checkpoint[key])}")
                
                # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹è¾æ›¸ã®ç¢ºèª
                if 'model_state_dict' in checkpoint:
                    analysis['model_state_dict_available'] = True
                    model_dict = checkpoint['model_state_dict']
                    analysis['model_parameters'] = {
                        'num_parameters': len(model_dict.keys()),
                        'parameter_shapes': {k: list(v.shape) for k, v in model_dict.items()},
                        'total_params': sum(v.numel() for v in model_dict.values())
                    }
                    print(f"    âœ… ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹è¾æ›¸: {len(model_dict)} ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                    print(f"    ğŸ“Š ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {analysis['model_parameters']['total_params']:,}")
                
                # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹ã®ç¢ºèª
                if 'optimizer_state_dict' in checkpoint:
                    analysis['optimizer_state_dict_available'] = True
                    print(f"    âœ… ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹: ä¿å­˜æ¸ˆã¿")
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                metadata_keys = ['config', 'learning_method', 'training_history', 'metadata', 'epoch', 'loss']
                for key in metadata_keys:
                    if key in checkpoint:
                        analysis['training_metadata'][key] = checkpoint[key]
                        print(f"    ğŸ“ {key}: {type(checkpoint[key])}")
                
                # å†æ§‹æˆå¯èƒ½æ€§ã®è©•ä¾¡
                has_model = analysis['model_state_dict_available']
                has_config = 'config' in checkpoint
                has_metadata = len(analysis['training_metadata']) > 0
                
                analysis['reconstruction_possible'] = has_model and (has_config or has_metadata)
                
                print(f"  ğŸ”§ å†æ§‹æˆå¯èƒ½æ€§: {'âœ… å¯èƒ½' if analysis['reconstruction_possible'] else 'âŒ å›°é›£'}")
                
            else:
                print(f"  âš ï¸ éæ¨™æº–å½¢å¼: {type(checkpoint)}")
                
        except Exception as e:
            print(f"  âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            analysis = {'error': str(e), 'reconstruction_possible': False}
            
        return analysis
    
    def test_model_reconstruction(self, model_path: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã®ãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ§ª ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆãƒ†ã‚¹ãƒˆ: {model_path}")
        print("-" * 50)
        
        test_result = {
            'model_path': model_path,
            'reconstruction_successful': False,
            'errors': [],
            'warnings': [],
            'reconstructed_components': []
        }
        
        if not analysis.get('reconstruction_possible', False):
            test_result['errors'].append("å†æ§‹æˆã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³")
            print("  âŒ å†æ§‹æˆä¸å¯: å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return test_result
        
        try:
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
            checkpoint = torch.load(model_path, map_location='cpu')
            print("  âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿æˆåŠŸ")
            
            # è¨­å®šæƒ…å ±ã®å¾©å…ƒ
            if 'config' in checkpoint:
                config = checkpoint['config']
                print(f"  âœ… è¨­å®šå¾©å…ƒ: {type(config)}")
                test_result['reconstructed_components'].append('config')
            else:
                test_result['warnings'].append("è¨­å®šæƒ…å ±ãªã—")
                
            # ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®æ¨å®š
            if 'model_state_dict' in checkpoint:
                model_dict = checkpoint['model_state_dict']
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‹ã‚‰æ§‹é€ ã‚’æ¨å®š
                param_info = []
                for name, param in model_dict.items():
                    param_info.append(f"{name}: {list(param.shape)}")
                    
                print(f"  ğŸ” ãƒ¢ãƒ‡ãƒ«æ§‹é€ æ¨å®š:")
                for info in param_info[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
                    print(f"    - {info}")
                if len(param_info) > 5:
                    print(f"    ... ä»– {len(param_info) - 5} å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                    
                test_result['reconstructed_components'].append('model_structure')
                
            # å­¦ç¿’å±¥æ­´ã®å¾©å…ƒ
            if 'training_history' in checkpoint:
                history = checkpoint['training_history']
                print(f"  ğŸ“ˆ å­¦ç¿’å±¥æ­´å¾©å…ƒ: {len(history.get('loss', []))} ã‚¨ãƒãƒƒã‚¯")
                test_result['reconstructed_components'].append('training_history')
                
            # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å¾©å…ƒ
            if 'optimizer_state_dict' in checkpoint:
                print(f"  âš™ï¸ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹å¾©å…ƒæˆåŠŸ")
                test_result['reconstructed_components'].append('optimizer')
                
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒ
            if 'metadata' in checkpoint:
                metadata = checkpoint['metadata']
                print(f"  ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒ: {len(metadata.keys()) if isinstance(metadata, dict) else 'N/A'} é …ç›®")
                test_result['reconstructed_components'].append('metadata')
                
            test_result['reconstruction_successful'] = True
            print("  ğŸ‰ ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆæˆåŠŸï¼")
            
        except Exception as e:
            test_result['errors'].append(str(e))
            print(f"  âŒ å†æ§‹æˆå¤±æ•—: {e}")
            
        return test_result
    
    def create_reconstruction_demo(self, model_path: str) -> bool:
        """å®Ÿéš›ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹æˆã—ã¦ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        print(f"\nğŸš€ ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆãƒ‡ãƒ¢: {model_path}")
        print("-" * 50)
        
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆç”¨ãƒœãƒ¼ãƒ‰çŠ¶æ…‹
            test_board = np.random.randint(-1, 2, (6, 5))
            test_position = (2, 2)
            
            print("  ğŸ“‹ ãƒ†ã‚¹ãƒˆç’°å¢ƒ:")
            print(f"    - ãƒœãƒ¼ãƒ‰ã‚µã‚¤ã‚º: {test_board.shape}")
            print(f"    - ãƒ†ã‚¹ãƒˆä½ç½®: {test_position}")
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸäºˆæ¸¬ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã«ä¾å­˜ï¼‰
            if 'model_state_dict' in checkpoint:
                model_dict = checkpoint['model_state_dict']
                print(f"  ğŸ§  ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {len(model_dict)}")
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±è¨ˆ
                total_params = sum(v.numel() for v in model_dict.values())
                param_mean = sum(v.mean().item() * v.numel() for v in model_dict.values()) / total_params
                param_std = np.sqrt(sum(((v - param_mean) ** 2).sum().item() for v in model_dict.values()) / total_params)
                
                print(f"    ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±è¨ˆ: å¹³å‡={param_mean:.6f}, æ¨™æº–åå·®={param_std:.6f}")
                
                # è¨­å®šæƒ…å ±ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if 'config' in checkpoint:
                    config = checkpoint['config']
                    print(f"  âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š:")
                    if isinstance(config, dict):
                        for key, value in config.items():
                            print(f"    - {key}: {value}")
                    else:
                        print(f"    - è¨­å®šã‚¿ã‚¤ãƒ—: {type(config)}")
                
                # å­¦ç¿’å±¥æ­´ã®ç¢ºèª
                if 'training_history' in checkpoint:
                    history = checkpoint['training_history']
                    if isinstance(history, dict) and 'loss' in history:
                        losses = history['loss']
                        if losses:
                            print(f"  ğŸ“ˆ å­¦ç¿’é€²æ—:")
                            print(f"    - ç·ã‚¨ãƒãƒƒã‚¯: {len(losses)}")
                            print(f"    - åˆæœŸæå¤±: {losses[0]:.6f}")
                            print(f"    - æœ€çµ‚æå¤±: {losses[-1]:.6f}")
                            print(f"    - æ”¹å–„ç‡: {((losses[0] - losses[-1]) / losses[0] * 100):.2f}%")
                
                print("  âœ… ãƒ¢ãƒ‡ãƒ«æ§‹é€ è§£æå®Œäº†")
                return True
                
        except Exception as e:
            print(f"  âŒ ãƒ‡ãƒ¢å®Ÿè¡Œå¤±æ•—: {e}")
            return False
        
        return False
    
    def verify_reinforcement_learning_evidence(self, model_path: str) -> Dict[str, Any]:
        """å¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ ã‚’æ¤œè¨¼"""
        print(f"\nğŸ¯ å¼·åŒ–å­¦ç¿’è¨¼æ‹ æ¤œè¨¼: {model_path}")
        print("-" * 50)
        
        evidence = {
            'has_replay_buffer': False,
            'has_target_network': False,
            'has_epsilon_decay': False,
            'has_q_values': False,
            'has_episode_rewards': False,
            'has_exploration_history': False,
            'reinforcement_learning_score': 0
        }
        
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            
            # å¼·åŒ–å­¦ç¿’ç‰¹æœ‰ã®è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            rl_indicators = {
                'replay_buffer': ['buffer', 'memory', 'experiences', 'transitions'],
                'target_network': ['target_model', 'target_net', 'target_state_dict'],
                'epsilon': ['epsilon', 'exploration_rate', 'eps'],
                'q_values': ['q_network', 'q_values', 'dqn'],
                'rewards': ['rewards', 'episode_rewards', 'cumulative_reward'],
                'episodes': ['episodes', 'episode_count', 'total_episodes']
            }
            
            print("  ğŸ” å¼·åŒ–å­¦ç¿’æŒ‡æ¨™ã®æ¤œç´¢:")
            
            for category, keywords in rl_indicators.items():
                found = False
                for key in checkpoint.keys():
                    if any(keyword in str(key).lower() for keyword in keywords):
                        found = True
                        break
                        
                # training_historyã®ä¸­ã‚‚ãƒã‚§ãƒƒã‚¯
                if 'training_history' in checkpoint and isinstance(checkpoint['training_history'], dict):
                    for key in checkpoint['training_history'].keys():
                        if any(keyword in str(key).lower() for keyword in keywords):
                            found = True
                            break
                
                # metadataã®ä¸­ã‚‚ãƒã‚§ãƒƒã‚¯
                if 'metadata' in checkpoint and isinstance(checkpoint['metadata'], dict):
                    for key in checkpoint['metadata'].keys():
                        if any(keyword in str(key).lower() for keyword in keywords):
                            found = True
                            break
                
                emoji = "âœ…" if found else "âŒ"
                print(f"    {emoji} {category}: {'ç™ºè¦‹' if found else 'æœªç™ºè¦‹'}")
                
                if found:
                    evidence[f'has_{category.lower()}'] = True
                    evidence['reinforcement_learning_score'] += 1
            
            # å­¦ç¿’å±¥æ­´ã®è©³ç´°åˆ†æ
            if 'training_history' in checkpoint:
                history = checkpoint['training_history']
                if isinstance(history, dict):
                    print(f"  ğŸ“Š å­¦ç¿’å±¥æ­´è©³ç´°:")
                    for key, value in history.items():
                        if isinstance(value, list):
                            print(f"    - {key}: {len(value)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
                        else:
                            print(f"    - {key}: {type(value)}")
            
            # ã‚¹ã‚³ã‚¢è©•ä¾¡
            max_score = len(rl_indicators)
            score_percentage = (evidence['reinforcement_learning_score'] / max_score) * 100
            
            print(f"\n  ğŸ“ˆ å¼·åŒ–å­¦ç¿’è¨¼æ‹ ã‚¹ã‚³ã‚¢: {evidence['reinforcement_learning_score']}/{max_score} ({score_percentage:.1f}%)")
            
            if score_percentage >= 70:
                print("  ğŸ¯ åˆ¤å®š: å¼·åŠ›ãªå¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ ")
            elif score_percentage >= 40:
                print("  ğŸ”„ åˆ¤å®š: éƒ¨åˆ†çš„ãªå¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ ") 
            else:
                print("  â“ åˆ¤å®š: å¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ ã¯é™å®šçš„")
                
        except Exception as e:
            print(f"  âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            evidence['error'] = str(e)
            
        return evidence
    
    def generate_verification_report(self) -> None:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\nğŸ“Š å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 70)
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'models_analyzed': len(self.available_models),
            'reconstruction_results': self.test_results
        }
        
        # å…¨ä½“çš„ãªè©•ä¾¡
        successful_reconstructions = sum(1 for result in self.test_results.values() 
                                       if result.get('reconstruction_successful', False))
        
        print(f"\nğŸ¯ ç·åˆçµæœ:")
        print(f"  ğŸ“ åˆ†æãƒ¢ãƒ‡ãƒ«æ•°: {report['models_analyzed']}")
        print(f"  âœ… å†æ§‹æˆæˆåŠŸ: {successful_reconstructions}")
        print(f"  ğŸ“Š æˆåŠŸç‡: {successful_reconstructions/len(self.available_models)*100:.1f}%")
        
        # å¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ è©•ä¾¡
        rl_evidence_scores = []
        for result in self.test_results.values():
            if 'rl_evidence' in result:
                score = result['rl_evidence'].get('reinforcement_learning_score', 0)
                rl_evidence_scores.append(score)
        
        if rl_evidence_scores:
            avg_rl_score = np.mean(rl_evidence_scores)
            print(f"  ğŸ§  å¹³å‡å¼·åŒ–å­¦ç¿’ã‚¹ã‚³ã‚¢: {avg_rl_score:.1f}/6.0")
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"model_persistence_verification_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”¬ å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»å¾©å…ƒæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 70)
    
    verifier = ModelPersistenceVerifier()
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    model_files = verifier.find_saved_models()
    
    if not model_files:
        print("\nâŒ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print("å¼·åŒ–å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:")
        print("  python rl_cqcnn_runner.py")
        return
    
    # 2. å„ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼
    for model_file in model_files:
        # æ§‹é€ åˆ†æ
        analysis = verifier.analyze_model_structure(model_file)
        
        # å†æ§‹æˆãƒ†ã‚¹ãƒˆ
        reconstruction_result = verifier.test_model_reconstruction(model_file, analysis)
        
        # å†æ§‹æˆãƒ‡ãƒ¢
        demo_success = verifier.create_reconstruction_demo(model_file)
        
        # å¼·åŒ–å­¦ç¿’è¨¼æ‹ æ¤œè¨¼
        rl_evidence = verifier.verify_reinforcement_learning_evidence(model_file)
        
        # çµæœä¿å­˜
        verifier.test_results[model_file] = {
            'analysis': analysis,
            'reconstruction': reconstruction_result,
            'demo_success': demo_success,
            'rl_evidence': rl_evidence
        }
    
    # 3. ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    verifier.generate_verification_report()
    
    print(f"\nğŸ‰ æ¤œè¨¼å®Œäº†!")
    print("çµè«–: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»å¾©å…ƒæ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã€å¼·åŒ–å­¦ç¿’ã®è¨¼æ‹ ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()