#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆNeuralQMapGenerator
å…¥åŠ›æ¬¡å…ƒã®å•é¡Œã‚’è§£æ±º
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Tuple

class FixedNeuralQMapGenerator:
    """ä¿®æ­£ç‰ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # å…¥åŠ›æ¬¡å…ƒã‚’æ­£ç¢ºã«è¨ˆç®—
        # ãƒœãƒ¼ãƒ‰çŠ¶æ…‹: 6*6 = 36
        # æ¨å®šçµ±è¨ˆ: 10
        # åˆè¨ˆ: 46
        self.input_dim = 36 + 10
        
        self.network = nn.Sequential(
            nn.Linear(self.input_dim, 64),   # 46 -> 64
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 32),                # 64 -> 32
            nn.ReLU(),
            nn.Linear(32, 144),               # 32 -> 144 (6*6*4)
            nn.Tanh()
        )
        
        # é‡ã¿ã‚’åˆæœŸåŒ–
        self._initialize_weights()
    
    def _initialize_weights(self):
        """é‡ã¿ã®åˆæœŸåŒ–"""
        for module in self.network.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def generate(self, board_state: np.ndarray, 
                estimations: Dict[Tuple[int, int], Dict[str, float]],
                my_pieces: Dict[Tuple[int, int], str],
                player: str) -> np.ndarray:
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ"""
        
        # 1. ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’1æ¬¡å…ƒåŒ–ï¼ˆ36æ¬¡å…ƒï¼‰
        board_features = board_state.flatten().astype(np.float32)
        
        # 2. æ¨å®šæƒ…å ±ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆ10æ¬¡å…ƒï¼‰
        est_features = self._extract_estimation_features(estimations, my_pieces)
        
        # 3. ç‰¹å¾´é‡ã‚’çµåˆï¼ˆ46æ¬¡å…ƒï¼‰
        all_features = np.concatenate([board_features, est_features])
        
        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®1å›ã®ã¿ï¼‰
        if not hasattr(self, '_debug_shown'):
            print(f"  [NeuralQMap] å…¥åŠ›æ¬¡å…ƒ: {len(all_features)} (ãƒœãƒ¼ãƒ‰:{len(board_features)} + æ¨å®š:{len(est_features)})")
            self._debug_shown = True
        
        # 4. ãƒ†ãƒ³ã‚½ãƒ«åŒ–
        input_tensor = torch.tensor(all_features, dtype=torch.float32).unsqueeze(0)
        
        # 5. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¨è«–
        with torch.no_grad():
            output = self.network(input_tensor)
            q_map_flat = output.squeeze(0).numpy()
        
        # 6. Qå€¤ãƒãƒƒãƒ—ã®å½¢çŠ¶ã«å¤‰æ› (6, 6, 4)
        q_map = q_map_flat.reshape(6, 6, 4)
        
        # 7. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨å¾Œå‡¦ç†
        q_map = self._postprocess_qmap(q_map, my_pieces, player, estimations)
        
        return q_map
    
    def _extract_estimation_features(self, estimations: Dict, my_pieces: Dict) -> np.ndarray:
        """æ¨å®šæƒ…å ±ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆ10æ¬¡å…ƒå›ºå®šï¼‰"""
        features = np.zeros(10, dtype=np.float32)
        
        if estimations:
            # æ¨å®šå€¤ã®çµ±è¨ˆ
            good_probs = [e['good_prob'] for e in estimations.values()]
            bad_probs = [e['bad_prob'] for e in estimations.values()]
            confidences = [e['confidence'] for e in estimations.values()]
            
            if good_probs:
                features[0] = np.mean(good_probs)      # å–„ç‰ç¢ºç‡ã®å¹³å‡
                features[1] = np.std(good_probs)       # å–„ç‰ç¢ºç‡ã®æ¨™æº–åå·®
                features[2] = np.max(good_probs)       # å–„ç‰ç¢ºç‡ã®æœ€å¤§å€¤
                features[3] = np.min(good_probs)       # å–„ç‰ç¢ºç‡ã®æœ€å°å€¤
            
            if confidences:
                features[4] = np.mean(confidences)     # ç¢ºä¿¡åº¦ã®å¹³å‡
                features[5] = np.max(confidences)      # ç¢ºä¿¡åº¦ã®æœ€å¤§å€¤
        
        # é§’æ•°æƒ…å ±
        features[6] = len(my_pieces) / 8.0            # è‡ªåˆ†ã®é§’æ•°ï¼ˆæ­£è¦åŒ–ï¼‰
        features[7] = len(estimations) / 8.0          # æ•µã®é§’æ•°ï¼ˆæ­£è¦åŒ–ï¼‰
        
        # é§’ã‚¿ã‚¤ãƒ—æƒ…å ±
        if my_pieces:
            good_count = sum(1 for p in my_pieces.values() if p == "good")
            features[8] = good_count / max(len(my_pieces), 1)  # å–„ç‰ã®å‰²åˆ
            features[9] = 1.0 - features[8]                    # æ‚ªç‰ã®å‰²åˆ
        
        return features
    
    def _postprocess_qmap(self, q_map: np.ndarray, my_pieces: Dict, 
                          player: str, estimations: Dict) -> np.ndarray:
        """Qå€¤ãƒãƒƒãƒ—ã®å¾Œå‡¦ç†"""
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        q_map = q_map * 5.0
        
        # è‡ªåˆ†ã®é§’ãŒãªã„ä½ç½®ã¯ç„¡åŠ¹åŒ–
        for y in range(6):
            for x in range(6):
                if (x, y) not in my_pieces:
                    q_map[y, x, :] = -100
        
        # å¢ƒç•Œå¤–ã¸ã®ç§»å‹•ã‚’ç„¡åŠ¹åŒ–
        for (x, y) in my_pieces:
            directions = [(-1, 0), (0, 1), (1, 0), (0, -1)]  # ä¸Šå³ä¸‹å·¦
            for dir_idx, (dx, dy) in enumerate(directions):
                new_x, new_y = x + dx, y + dy
                if not (0 <= new_x < 6 and 0 <= new_y < 6):
                    q_map[y, x, dir_idx] = -100
        
        # åŸºæœ¬çš„ãªæˆ¦ç•¥ã‚’è¿½åŠ 
        for (x, y), piece_type in my_pieces.items():
            # å‰é€²ãƒœãƒ¼ãƒŠã‚¹
            if player == "A":
                q_map[y, x, 2] += 1.0  # ä¸‹æ–¹å‘
            else:
                q_map[y, x, 0] += 1.0  # ä¸Šæ–¹å‘
            
            # è„±å‡ºãƒœãƒ¼ãƒŠã‚¹ï¼ˆå–„ç‰ã®ã¿ï¼‰
            if piece_type == "good":
                escape_positions = [(0, 5), (5, 5)] if player == "A" else [(0, 0), (5, 0)]
                for escape_x, escape_y in escape_positions:
                    if abs(x - escape_x) + abs(y - escape_y) == 1:
                        # è„±å‡ºå£ã«éš£æ¥ã—ã¦ã„ã‚‹
                        for dir_idx, (dx, dy) in enumerate([(-1, 0), (0, 1), (1, 0), (0, -1)]):
                            if x + dx == escape_x and y + dy == escape_y:
                                q_map[y, x, dir_idx] += 10.0
        
        return q_map
    
    def get_generator_name(self) -> str:
        return "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«Qå€¤ç”Ÿæˆ(ä¿®æ­£ç‰ˆ)"


# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_fixed_neural_qmap():
    """ä¿®æ­£ç‰ˆã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ä¿®æ­£ç‰ˆNeuralQMapGeneratorã®ãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ä½œæˆ
    generator = FixedNeuralQMapGenerator()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    board_state = np.random.randint(-1, 2, (6, 6))
    estimations = {
        (2, 3): {'good_prob': 0.7, 'bad_prob': 0.3, 'confidence': 0.8},
        (3, 4): {'good_prob': 0.4, 'bad_prob': 0.6, 'confidence': 0.6}
    }
    my_pieces = {
        (1, 1): "good",
        (2, 1): "bad",
        (3, 2): "good"
    }
    
    # Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ
    q_map = generator.generate(board_state, estimations, my_pieces, "A")
    
    print(f"âœ… Qå€¤ãƒãƒƒãƒ—ç”ŸæˆæˆåŠŸ")
    print(f"  å½¢çŠ¶: {q_map.shape}")
    print(f"  æœ€å¤§å€¤: {np.max(q_map):.2f}")
    print(f"  æœ€å°å€¤: {np.min(q_map):.2f}")
    print(f"  å¹³å‡å€¤: {np.mean(q_map[q_map > -100]):.2f}")  # ç„¡åŠ¹å€¤ã‚’é™¤ã
    
    # ç‰¹å®šã®é§’ã®Qå€¤ã‚’ç¢ºèª
    for (x, y), piece_type in my_pieces.items():
        print(f"\né§’({x},{y}) [{piece_type}] ã®Qå€¤:")
        directions = ["ä¸Š", "å³", "ä¸‹", "å·¦"]
        for dir_idx, dir_name in enumerate(directions):
            q_value = q_map[y, x, dir_idx]
            if q_value > -100:
                print(f"  {dir_name}: {q_value:.2f}")


if __name__ == "__main__":
    test_fixed_neural_qmap()
