#!/usr/bin/env python3
"""
åˆ†é›¢å‹ã‚·ã‚¹ãƒ†ãƒ :
1. CQCNNã«ã‚ˆã‚‹æ•µé§’ã‚¿ã‚¤ãƒ—æ¨å®š
2. æ¨å®šçµæœã‹ã‚‰Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, List, Any
from dataclasses import dataclass
import json


# ================================================================================
# Part 1: CQCNNã«ã‚ˆã‚‹æ•µé§’æ¨å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# ================================================================================


@dataclass
class PieceEstimation:
    """é§’æ¨å®šçµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""

    position: Tuple[int, int]
    good_probability: float  # å–„ç‰ã§ã‚ã‚‹ç¢ºç‡
    bad_probability: float  # æ‚ªç‰ã§ã‚ã‚‹ç¢ºç‡
    confidence: float  # æ¨å®šã®ç¢ºä¿¡åº¦

    def to_dict(self) -> dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "position": self.position,
            "good_prob": self.good_probability,
            "bad_prob": self.bad_probability,
            "confidence": self.confidence,
        }


class CQCNNPieceEstimator(nn.Module):
    """æ•µé§’ã‚¿ã‚¤ãƒ—æ¨å®šå°‚ç”¨CQCNN"""

    def __init__(self, n_qubits: int = 8, n_layers: int = 3):
        super().__init__()
        self.n_qubits = n_qubits
        self.n_layers = n_layers

        # ç‰¹å¾´æŠ½å‡ºå±¤
        self.feature_conv = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # 3ch: è‡ªé§’/æ•µé§’/ç©º
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 6x6 -> 3x3
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
        )

        # é‡å­å›è·¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
        self.quantum_params = nn.Parameter(torch.randn(n_layers, n_qubits, 3))

        # é§’ã‚¿ã‚¤ãƒ—æ¨å®šãƒ˜ãƒƒãƒ‰
        self.piece_type_head = nn.Sequential(
            nn.Linear(64 * 3 * 3 + n_qubits, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 2),  # [good_prob, bad_prob]
        )

        # ç¢ºä¿¡åº¦æ¨å®šãƒ˜ãƒƒãƒ‰
        self.confidence_head = nn.Sequential(
            nn.Linear(64 * 3 * 3 + n_qubits, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid()
        )

    def quantum_circuit_simulation(self, x: torch.Tensor) -> torch.Tensor:
        """é‡å­å›è·¯ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        batch_size = x.shape[0]

        # ç°¡æ˜“çš„ãªé‡å­è¨ˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        q_state = torch.zeros(batch_size, self.n_qubits)

        for layer in range(self.n_layers):
            # å›è»¢ã‚²ãƒ¼ãƒˆ
            for q in range(self.n_qubits):
                rotation = self.quantum_params[layer, q]
                q_state[:, q] = torch.sin(rotation[0] * x[:, q % x.shape[1]]) * torch.cos(
                    rotation[1] * x[:, (q + 1) % x.shape[1]]
                ) + torch.tanh(rotation[2] * q_state[:, q])

        return q_state

    def forward(self, board_state: torch.Tensor, target_positions: List[Tuple[int, int]]) -> List[PieceEstimation]:
        """
        æ•µé§’ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š

        Args:
            board_state: ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ (batch_size, 3, 6, 6)
            target_positions: æ¨å®šå¯¾è±¡ã®æ•µé§’ä½ç½®ãƒªã‚¹ãƒˆ

        Returns:
            å„æ•µé§’ã®æ¨å®šçµæœãƒªã‚¹ãƒˆ
        """
        batch_size = board_state.shape[0]

        # CNNç‰¹å¾´æŠ½å‡º
        conv_features = self.feature_conv(board_state)
        conv_flat = conv_features.view(batch_size, -1)

        # é‡å­ç‰¹å¾´æŠ½å‡º
        board_flat = board_state.view(batch_size, -1)
        quantum_features = self.quantum_circuit_simulation(board_flat[:, : self.n_qubits])

        # ç‰¹å¾´çµåˆ
        combined_features = torch.cat([conv_flat, quantum_features], dim=1)

        # å„é§’ä½ç½®ã«å¯¾ã™ã‚‹æ¨å®š
        estimations = []
        for pos in target_positions:
            # ä½ç½®ç‰¹æœ‰ã®ç‰¹å¾´ã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            pos_encoding = torch.tensor([pos[0] / 5.0, pos[1] / 5.0], dtype=torch.float32)
            pos_encoding = pos_encoding.unsqueeze(0).repeat(batch_size, 1)

            # ã‚¿ã‚¤ãƒ—æ¨å®š
            type_logits = self.piece_type_head(combined_features)
            type_probs = F.softmax(type_logits, dim=1)

            # ç¢ºä¿¡åº¦æ¨å®š
            confidence = self.confidence_head(combined_features)

            # ãƒãƒƒãƒå¹³å‡ã‚’å–å¾—ï¼ˆå˜ä¸€æ¨å®šã®å ´åˆï¼‰
            if batch_size == 1:
                estimation = PieceEstimation(
                    position=pos,
                    good_probability=type_probs[0, 0].item(),
                    bad_probability=type_probs[0, 1].item(),
                    confidence=confidence[0, 0].item(),
                )
            else:
                # ãƒãƒƒãƒå…¨ä½“ã®å¹³å‡
                estimation = PieceEstimation(
                    position=pos,
                    good_probability=type_probs[:, 0].mean().item(),
                    bad_probability=type_probs[:, 1].mean().item(),
                    confidence=confidence.mean().item(),
                )

            estimations.append(estimation)

        return estimations


class PieceEstimationDataExporter:
    """é§’æ¨å®šãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç®¡ç†"""

    def __init__(self, estimator: CQCNNPieceEstimator):
        self.estimator = estimator
        self.estimation_history = []

    def estimate_and_export(self, game_state: dict) -> Dict[str, Any]:
        """
        ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã‹ã‚‰é§’æ¨å®šã‚’å®Ÿè¡Œã—ã€çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            game_state: ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã®è¾æ›¸
                - board: 6x6ã®ãƒœãƒ¼ãƒ‰é…åˆ—
                - current_player: ç¾åœ¨ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
                - turn: ã‚¿ãƒ¼ãƒ³æ•°

        Returns:
            ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        board = np.array(game_state["board"])
        current_player = game_state["current_player"]
        turn = game_state.get("turn", 0)

        # ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        board_tensor = self._prepare_board_tensor(board, current_player)

        # æ•µé§’ä½ç½®ã‚’ç‰¹å®š
        enemy_positions = self._find_enemy_positions(board, current_player)

        if not enemy_positions:
            return {"turn": turn, "player": current_player, "estimations": [], "summary": {"total_enemies": 0}}

        # æ¨å®šå®Ÿè¡Œ
        with torch.no_grad():
            estimations = self.estimator(board_tensor, enemy_positions)

        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        export_data = {
            "turn": turn,
            "player": current_player,
            "estimations": [est.to_dict() for est in estimations],
            "summary": self._create_summary(estimations),
            "board_state": board.tolist(),
        }

        # å±¥æ­´ã«è¿½åŠ 
        self.estimation_history.append(export_data)

        return export_data

    def _prepare_board_tensor(self, board: np.ndarray, current_player: str) -> torch.Tensor:
        """ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›"""
        tensor = torch.zeros(1, 3, 6, 6)  # batch_size=1

        player_val = 1 if current_player == "A" else -1
        enemy_val = -player_val

        # ãƒãƒ£ãƒ³ãƒãƒ«0: è‡ªé§’
        tensor[0, 0] = torch.from_numpy((board == player_val).astype(np.float32))
        # ãƒãƒ£ãƒ³ãƒãƒ«1: æ•µé§’
        tensor[0, 1] = torch.from_numpy((board == enemy_val).astype(np.float32))
        # ãƒãƒ£ãƒ³ãƒãƒ«2: ç©ºãƒã‚¹
        tensor[0, 2] = torch.from_numpy((board == 0).astype(np.float32))

        return tensor

    def _find_enemy_positions(self, board: np.ndarray, current_player: str) -> List[Tuple[int, int]]:
        """æ•µé§’ã®ä½ç½®ã‚’ç‰¹å®š"""
        enemy_val = -1 if current_player == "A" else 1
        positions = []

        for y in range(6):
            for x in range(6):
                if board[y, x] == enemy_val:
                    positions.append((x, y))

        return positions

    def _create_summary(self, estimations: List[PieceEstimation]) -> dict:
        """æ¨å®šçµæœã®ã‚µãƒãƒªãƒ¼ä½œæˆ"""
        if not estimations:
            return {"total_enemies": 0}

        good_count = sum(1 for e in estimations if e.good_probability > 0.5)
        bad_count = sum(1 for e in estimations if e.bad_probability > 0.5)
        avg_confidence = np.mean([e.confidence for e in estimations])

        return {
            "total_enemies": len(estimations),
            "estimated_good": good_count,
            "estimated_bad": bad_count,
            "average_confidence": float(avg_confidence),
            "high_confidence_count": sum(1 for e in estimations if e.confidence > 0.7),
        }

    def save_to_file(self, filepath: str):
        """æ¨å®šå±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(filepath, "w") as f:
            json.dump(self.estimation_history, f, indent=2)
        print(f"ğŸ“ æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filepath}")


# ================================================================================
# Part 2: Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# ================================================================================


class QValueMapGenerator:
    """é§’æ¨å®šçµæœã‹ã‚‰Qå€¤ãƒãƒƒãƒ—ã‚’ç”Ÿæˆ"""

    def __init__(self, board_size: int = 6):
        self.board_size = board_size

        # Qå€¤è¨ˆç®—ç”¨ã®é‡ã¿
        self.weights = {
            "capture_good": 10.0,  # å–„ç‰æ•ç²ã®ä¾¡å€¤
            "capture_bad": -5.0,  # æ‚ªç‰æ•ç²ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
            "escape_progress": 8.0,  # è„±å‡ºã¸ã®å‰é€²
            "center_control": 2.0,  # ä¸­å¤®åˆ¶å¾¡
            "safety": 3.0,  # å®‰å…¨æ€§
            "threat": 4.0,  # è„…å¨åº¦
            "uncertainty_penalty": -1.0,  # ä¸ç¢ºå®Ÿæ€§ãƒšãƒŠãƒ«ãƒ†ã‚£
        }

    def generate_q_map(
        self,
        board_state: np.ndarray,
        piece_estimations: List[Dict],
        current_player: str,
        my_pieces: Dict[Tuple[int, int], str],
    ) -> np.ndarray:
        """
        é§’æ¨å®šçµæœã‹ã‚‰Qå€¤ãƒãƒƒãƒ—ã‚’ç”Ÿæˆ

        Args:
            board_state: ç¾åœ¨ã®ãƒœãƒ¼ãƒ‰çŠ¶æ…‹
            piece_estimations: é§’æ¨å®šçµæœã®ãƒªã‚¹ãƒˆ
            current_player: ç¾åœ¨ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
            my_pieces: è‡ªåˆ†ã®é§’æƒ…å ± {ä½ç½®: ã‚¿ã‚¤ãƒ—}

        Returns:
            Qå€¤ãƒãƒƒãƒ— (6, 6, 4) - å„ä½ç½®ã®4æ–¹å‘ã¸ã®ç§»å‹•ä¾¡å€¤
        """
        q_map = np.zeros((self.board_size, self.board_size, 4))  # 4æ–¹å‘: ä¸Šå³ä¸‹å·¦

        # æ¨å®šçµæœã‚’ä½ç½®ãƒ™ãƒ¼ã‚¹ã®è¾æ›¸ã«å¤‰æ›
        estimations_dict = {}
        for est in piece_estimations:
            pos = tuple(est["position"])
            estimations_dict[pos] = est

        # å„è‡ªé§’ã«å¯¾ã—ã¦Qå€¤ã‚’è¨ˆç®—
        for piece_pos, piece_type in my_pieces.items():
            x, y = piece_pos

            # 4æ–¹å‘ã®ç§»å‹•ã‚’è©•ä¾¡
            directions = [(-1, 0), (0, 1), (1, 0), (0, -1)]  # ä¸Šå³ä¸‹å·¦

            for dir_idx, (dx, dy) in enumerate(directions):
                new_x, new_y = x + dx, y + dy

                # å¢ƒç•Œãƒã‚§ãƒƒã‚¯
                if not (0 <= new_x < self.board_size and 0 <= new_y < self.board_size):
                    q_map[y, x, dir_idx] = -100  # ç§»å‹•ä¸å¯
                    continue

                # Qå€¤è¨ˆç®—
                q_value = self._calculate_position_value(
                    from_pos=(x, y),
                    to_pos=(new_x, new_y),
                    piece_type=piece_type,
                    board_state=board_state,
                    estimations_dict=estimations_dict,
                    current_player=current_player,
                )

                q_map[y, x, dir_idx] = q_value

        return q_map

    def _calculate_position_value(
        self,
        from_pos: Tuple[int, int],
        to_pos: Tuple[int, int],
        piece_type: str,
        board_state: np.ndarray,
        estimations_dict: Dict,
        current_player: str,
    ) -> float:
        """ç‰¹å®šã®ç§»å‹•ã«å¯¾ã™ã‚‹Qå€¤ã‚’è¨ˆç®—"""
        q_value = 0.0

        # 1. é§’æ•ç²ã®è©•ä¾¡
        if to_pos in estimations_dict:
            est = estimations_dict[to_pos]
            good_prob = est["good_prob"]
            bad_prob = est["bad_prob"]
            confidence = est["confidence"]

            # æœŸå¾…å€¤è¨ˆç®—
            capture_value = good_prob * self.weights["capture_good"] + bad_prob * self.weights["capture_bad"]

            # ç¢ºä¿¡åº¦ã§é‡ã¿ä»˜ã‘
            q_value += capture_value * confidence

            # ä¸ç¢ºå®Ÿæ€§ãƒšãƒŠãƒ«ãƒ†ã‚£
            if confidence < 0.5:
                q_value += self.weights["uncertainty_penalty"]

        # 2. è„±å‡ºã¸ã®å‰é€²è©•ä¾¡ï¼ˆå–„ç‰ã®å ´åˆï¼‰
        if piece_type == "good":
            escape_value = self._evaluate_escape_progress(from_pos, to_pos, current_player)
            q_value += escape_value * self.weights["escape_progress"]

        # 3. ä½ç½®ä¾¡å€¤è©•ä¾¡
        position_value = self._evaluate_position(to_pos, current_player)
        q_value += position_value

        # 4. å®‰å…¨æ€§è©•ä¾¡
        safety_value = self._evaluate_safety(to_pos, board_state, estimations_dict)
        q_value += safety_value * self.weights["safety"]

        # 5. è„…å¨å‰µå‡ºè©•ä¾¡
        threat_value = self._evaluate_threat_creation(to_pos, estimations_dict)
        q_value += threat_value * self.weights["threat"]

        return q_value

    def _evaluate_escape_progress(self, from_pos: Tuple[int, int], to_pos: Tuple[int, int], player: str) -> float:
        """è„±å‡ºã¸ã®å‰é€²åº¦ã‚’è©•ä¾¡"""
        if player == "A":
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã¯ä¸Šæ–¹å‘ï¼ˆYå¢—åŠ ï¼‰ãŒå‰é€²
            progress = (to_pos[1] - from_pos[1]) / 5.0
            # è„±å‡ºå£ã¸ã®æ¥è¿‘ãƒœãƒ¼ãƒŠã‚¹
            if to_pos[1] == 5 and (to_pos[0] == 0 or to_pos[0] == 5):
                progress += 1.0
        else:
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã¯ä¸‹æ–¹å‘ï¼ˆYæ¸›å°‘ï¼‰ãŒå‰é€²
            progress = (from_pos[1] - to_pos[1]) / 5.0
            # è„±å‡ºå£ã¸ã®æ¥è¿‘ãƒœãƒ¼ãƒŠã‚¹
            if to_pos[1] == 0 and (to_pos[0] == 0 or to_pos[0] == 5):
                progress += 1.0

        return max(0, progress)

    def _evaluate_position(self, pos: Tuple[int, int], player: str) -> float:
        """ä½ç½®ã®æˆ¦ç•¥çš„ä¾¡å€¤ã‚’è©•ä¾¡"""
        x, y = pos
        value = 0.0

        # ä¸­å¤®åˆ¶å¾¡ãƒœãƒ¼ãƒŠã‚¹
        center_distance = abs(x - 2.5) + abs(y - 2.5)
        value += self.weights["center_control"] * (1.0 - center_distance / 5.0)

        # å‰ç·šãƒœãƒ¼ãƒŠã‚¹
        if player == "A":
            value += y / 5.0  # ä¸Šæ–¹å‘ã¸ã®é€²å‡º
        else:
            value += (5 - y) / 5.0  # ä¸‹æ–¹å‘ã¸ã®é€²å‡º

        return value

    def _evaluate_safety(self, pos: Tuple[int, int], board_state: np.ndarray, estimations_dict: Dict) -> float:
        """ä½ç½®ã®å®‰å…¨æ€§ã‚’è©•ä¾¡"""
        x, y = pos
        danger = 0.0

        # å‘¨å›²ã®æ•µé§’ã«ã‚ˆã‚‹è„…å¨ã‚’è©•ä¾¡
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue

                check_x, check_y = x + dx, y + dy
                if (check_x, check_y) in estimations_dict:
                    est = estimations_dict[(check_x, check_y)]
                    # å–„ç‰ã®å¯èƒ½æ€§ãŒé«˜ã„æ•µé§’ã¯è„…å¨åº¦ãŒé«˜ã„
                    threat_level = est["good_prob"] * est["confidence"]
                    distance = max(abs(dx), abs(dy))
                    danger += threat_level / distance

        # å®‰å…¨æ€§ã¯è„…å¨åº¦ã®é€†æ•°
        safety = 1.0 / (1.0 + danger)
        return safety

    def _evaluate_threat_creation(self, pos: Tuple[int, int], estimations_dict: Dict) -> float:
        """è„…å¨å‰µå‡ºèƒ½åŠ›ã‚’è©•ä¾¡"""
        x, y = pos
        threat = 0.0

        # ç§»å‹•å…ˆã‹ã‚‰æ”»æ’ƒå¯èƒ½ãªæ•µé§’ã‚’è©•ä¾¡
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if abs(dx) + abs(dy) != 1:  # 4æ–¹å‘ã®ã¿
                    continue

                target_x, target_y = x + dx, y + dy
                if (target_x, target_y) in estimations_dict:
                    est = estimations_dict[(target_x, target_y)]
                    # å–„ç‰ã®å¯èƒ½æ€§ãŒé«˜ã„æ•µé§’ã¸ã®è„…å¨å‰µå‡ºä¾¡å€¤
                    threat += est["good_prob"] * est["confidence"]

        return threat

    def export_q_map(self, q_map: np.ndarray, filepath: str):
        """Qå€¤ãƒãƒƒãƒ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        export_data = {
            "shape": q_map.shape,
            "q_values": q_map.tolist(),
            "statistics": {
                "max_q": float(np.max(q_map)),
                "min_q": float(np.min(q_map)),
                "mean_q": float(np.mean(q_map)),
                "std_q": float(np.std(q_map)),
            },
        }

        with open(filepath, "w") as f:
            json.dump(export_data, f, indent=2)
        print(f"ğŸ“Š Qå€¤ãƒãƒƒãƒ—ã‚’ä¿å­˜: {filepath}")


# ================================================================================
# Part 3: çµ±åˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 
# ================================================================================


class IntegratedCQCNNSystem:
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ : é§’æ¨å®šâ†’Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ"""

    def __init__(self, n_qubits: int = 8, n_layers: int = 3):
        # é§’æ¨å®šå™¨
        self.estimator = CQCNNPieceEstimator(n_qubits, n_layers)
        self.exporter = PieceEstimationDataExporter(self.estimator)

        # Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆå™¨
        self.q_generator = QValueMapGenerator()

        # å®Ÿè¡Œå±¥æ­´
        self.execution_history = []

    def process_game_state(self, game_state: dict, my_pieces: dict) -> Tuple[Dict, np.ndarray]:
        """
        ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã‚’å‡¦ç†ã—ã¦é§’æ¨å®šã¨Qå€¤ãƒãƒƒãƒ—ã‚’ç”Ÿæˆ

        Args:
            game_state: ã‚²ãƒ¼ãƒ çŠ¶æ…‹
            my_pieces: è‡ªåˆ†ã®é§’æƒ…å ±

        Returns:
            (é§’æ¨å®šçµæœ, Qå€¤ãƒãƒƒãƒ—)
        """
        # Step 1: é§’æ¨å®šå®Ÿè¡Œ
        estimation_data = self.exporter.estimate_and_export(game_state)

        # Step 2: Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆ
        q_map = self.q_generator.generate_q_map(
            board_state=np.array(game_state["board"]),
            piece_estimations=estimation_data["estimations"],
            current_player=game_state["current_player"],
            my_pieces=my_pieces,
        )

        # å±¥æ­´è¨˜éŒ²
        self.execution_history.append(
            {
                "turn": game_state.get("turn", 0),
                "estimation": estimation_data,
                "q_map_stats": {
                    "max_q": float(np.max(q_map)),
                    "min_q": float(np.min(q_map)),
                    "mean_q": float(np.mean(q_map)),
                },
            }
        )

        return estimation_data, q_map

    def save_all_data(self, base_path: str):
        """å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        import os

        os.makedirs(base_path, exist_ok=True)

        # é§’æ¨å®šãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self.exporter.save_to_file(f"{base_path}/piece_estimations.json")

        # å®Ÿè¡Œå±¥æ­´ä¿å­˜
        with open(f"{base_path}/execution_history.json", "w") as f:
            json.dump(self.execution_history, f, indent=2)

        print(f"âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ {base_path} ã«ä¿å­˜å®Œäº†")


# ================================================================================
# ãƒ‡ãƒ¢å®Ÿè¡Œ
# ================================================================================


def demo():
    """ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ğŸš€ åˆ†é›¢å‹CQCNNé§’æ¨å®šï¼†Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆãƒ‡ãƒ¢")
    print("=" * 60)

    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = IntegratedCQCNNSystem(n_qubits=8, n_layers=3)

    # ã‚µãƒ³ãƒ—ãƒ«ã‚²ãƒ¼ãƒ çŠ¶æ…‹
    game_state = {
        "board": [
            [1, 1, 0, 0, -1, -1],
            [1, 1, 0, 0, -1, -1],
            [0, 0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0, 0],
            [1, 0, 0, 0, 0, -1],
            [0, 0, 0, 0, -1, -1],
        ],
        "current_player": "A",
        "turn": 10,
    }

    # è‡ªåˆ†ã®é§’æƒ…å ±
    my_pieces = {(0, 0): "good", (1, 0): "good", (0, 1): "bad", (1, 1): "bad", (0, 4): "good"}

    # å‡¦ç†å®Ÿè¡Œ
    print("\nğŸ“Š é§’æ¨å®šå®Ÿè¡Œä¸­...")
    estimation_data, q_map = system.process_game_state(game_state, my_pieces)

    # çµæœè¡¨ç¤º
    print("\nğŸ¯ é§’æ¨å®šçµæœ:")
    for est in estimation_data["estimations"]:
        print(
            f"  ä½ç½®{est['position']}: å–„ç‰ç¢ºç‡={est['good_prob']:.2f}, "
            f"æ‚ªç‰ç¢ºç‡={est['bad_prob']:.2f}, ç¢ºä¿¡åº¦={est['confidence']:.2f}"
        )

    print("\nğŸ“ˆ æ¨å®šã‚µãƒãƒªãƒ¼:")
    summary = estimation_data["summary"]
    print(f"  æ•µé§’ç·æ•°: {summary['total_enemies']}")
    print(f"  æ¨å®šå–„ç‰: {summary['estimated_good']}")
    print(f"  æ¨å®šæ‚ªç‰: {summary['estimated_bad']}")
    print(f"  å¹³å‡ç¢ºä¿¡åº¦: {summary['average_confidence']:.3f}")

    print("\nğŸ—ºï¸ Qå€¤ãƒãƒƒãƒ—çµ±è¨ˆ:")
    print(f"  æœ€å¤§Qå€¤: {np.max(q_map):.2f}")
    print(f"  æœ€å°Qå€¤: {np.min(q_map):.2f}")
    print(f"  å¹³å‡Qå€¤: {np.mean(q_map):.2f}")

    # æœ€é©æ‰‹ã®ææ¡ˆ
    best_q = -float("inf")
    best_move = None
    for piece_pos in my_pieces:
        x, y = piece_pos
        for dir_idx, (dx, dy) in enumerate([(-1, 0), (0, 1), (1, 0), (0, -1)]):
            if q_map[y, x, dir_idx] > best_q:
                best_q = q_map[y, x, dir_idx]
                best_move = (piece_pos, (x + dx, y + dy))

    if best_move:
        print(f"\nğŸ’¡ æ¨å¥¨æ‰‹: {best_move[0]} â†’ {best_move[1]} (Qå€¤: {best_q:.2f})")

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    system.save_all_data("cqcnn_output")
    print("\nâœ… ãƒ‡ãƒ¢å®Œäº†ï¼")


if __name__ == "__main__":
    demo()
