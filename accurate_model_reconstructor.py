#!/usr/bin/env python3
"""
æ­£ç¢ºãªå¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚·ã‚¹ãƒ†ãƒ 
ä¿å­˜ã•ã‚ŒãŸå½¢çŠ¶æƒ…å ±ã‚’ä½¿ã£ã¦å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import os

def analyze_checkpoint_structure(checkpoint_path: str) -> Dict[str, Any]:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ§‹é€ ã‚’è©³ç´°åˆ†æ"""
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    structure = {}
    
    if 'estimator_state' in checkpoint:
        estimator_dict = checkpoint['estimator_state']
        structure['estimator'] = {}
        
        for name, param in estimator_dict.items():
            structure['estimator'][name] = {
                'shape': list(param.shape),
                'dtype': str(param.dtype),
                'size': param.numel()
            }
    
    return structure

class DynamicCQCNNEstimator(nn.Module):
    """å‹•çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‚’èª¿æ•´ã™ã‚‹CQCNNæ¨å®šå™¨"""
    
    def __init__(self, param_shapes: Dict[str, List[int]]):
        super().__init__()
        
        self.param_shapes = param_shapes
        self.build_from_shapes()
        
    def build_from_shapes(self):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‹ã‚‰å‹•çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰"""
        
        # é‡å­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŠ½å‡º
        if 'quantum_params' in self.param_shapes:
            q_shape = self.param_shapes['quantum_params']
            self.n_layers, self.n_qubits, _ = q_shape
            self.quantum_params = nn.Parameter(torch.randn(*q_shape) * 0.1)
        
        # ç‰¹å¾´æŠ½å‡ºãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ§‹ç¯‰
        conv_layers = []
        layer_idx = 0
        
        # feature_convå±¤ã‚’é †ç•ªã«æ§‹ç¯‰
        while True:
            weight_key = f'feature_conv.{layer_idx}.weight'
            bias_key = f'feature_conv.{layer_idx}.bias'
            
            if weight_key in self.param_shapes:
                w_shape = self.param_shapes[weight_key]
                if len(w_shape) == 4:  # Conv2d
                    out_channels, in_channels, kh, kw = w_shape
                    conv_layers.append(nn.Conv2d(in_channels, out_channels, (kh, kw), padding=1 if kh == 3 else 0))
                elif len(w_shape) == 2:  # Linear
                    out_features, in_features = w_shape
                    conv_layers.append(nn.Linear(in_features, out_features))
                    
                layer_idx += 1
                
                # æ¬¡ãŒãƒã‚¤ã‚¢ã‚¹ã§ãªã„å ´åˆã¯Activationã‚’è¿½åŠ 
                next_weight_key = f'feature_conv.{layer_idx}.weight'
                if next_weight_key in self.param_shapes:
                    conv_layers.append(nn.ReLU())
                
            else:
                break
        
        # æœ€å¾Œã«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆæ¨å®šï¼‰
        if len(conv_layers) > 0:
            conv_layers.append(nn.AdaptiveAvgPool2d((2, 2)))
        
        self.feature_conv = nn.Sequential(*conv_layers)
        
        # piece_type_head ã®æ§‹ç¯‰
        piece_type_layers = []
        layer_idx = 0
        
        while True:
            weight_key = f'piece_type_head.{layer_idx}.weight'
            if weight_key in self.param_shapes:
                w_shape = self.param_shapes[weight_key]
                out_features, in_features = w_shape
                piece_type_layers.append(nn.Linear(in_features, out_features))
                
                # æ¬¡ãŒDropoutã‹ReLUã‹åˆ¤å®š
                next_idx = layer_idx + 1
                if f'piece_type_head.{next_idx}.weight' in self.param_shapes:
                    if next_idx == 2:  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆä½ç½®ã®æ¨å®š
                        piece_type_layers.append(nn.ReLU())
                        piece_type_layers.append(nn.Dropout(0.3))
                    else:
                        piece_type_layers.append(nn.ReLU())
                        
                layer_idx += 1
            else:
                break
        
        self.piece_type_head = nn.Sequential(*piece_type_layers)
        
        # confidence_head ã®æ§‹ç¯‰
        confidence_layers = []
        layer_idx = 0
        
        while True:
            weight_key = f'confidence_head.{layer_idx}.weight'
            if weight_key in self.param_shapes:
                w_shape = self.param_shapes[weight_key]
                out_features, in_features = w_shape
                confidence_layers.append(nn.Linear(in_features, out_features))
                
                # æœ€å¾Œã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãªã‘ã‚Œã°ReLUè¿½åŠ 
                next_key = f'confidence_head.{layer_idx + 1}.weight'
                if next_key in self.param_shapes:
                    confidence_layers.append(nn.ReLU())
                
                layer_idx += 1
            else:
                break
        
        self.confidence_head = nn.Sequential(*confidence_layers)
        
    def quantum_circuit(self, x):
        """ç°¡æ˜“é‡å­å›è·¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not hasattr(self, 'quantum_params'):
            return torch.zeros(x.size(0), 8)
            
        batch_size = x.size(0)
        quantum_state = torch.zeros(batch_size, self.n_qubits)
        
        for layer in range(self.n_layers):
            for qubit in range(self.n_qubits):
                angle = self.quantum_params[layer, qubit]
                quantum_state[:, qubit] += torch.sin(angle[0]) * x[:, qubit % x.size(1)]
                quantum_state[:, qubit] += torch.cos(angle[1]) * x[:, (qubit + 1) % x.size(1)]
                quantum_state[:, qubit] = torch.tanh(quantum_state[:, qubit] * angle[2])
        
        return quantum_state
        
    def forward(self, x):
        """é †ä¼æ’­"""
        batch_size = x.size(0)
        
        # å…¥åŠ›ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ã«å¤‰æ›
        if x.dim() == 2:
            x = x.view(batch_size, 25)
            x_3d = torch.zeros(batch_size, 3, 5, 5)
            x_3d[:, 0] = x.view(batch_size, 5, 5)
            x_3d[:, 1] = (x > 0).float().view(batch_size, 5, 5)
            x_3d[:, 2] = (x < 0).float().view(batch_size, 5, 5)
            x = x_3d
        
        # ç‰¹å¾´æŠ½å‡º
        conv_features = self.feature_conv(x)
        if conv_features.dim() > 2:
            conv_features = conv_features.view(batch_size, -1)
        
        # é‡å­å›è·¯
        quantum_input = x.view(batch_size, -1)
        if hasattr(self, 'n_qubits'):
            quantum_input = quantum_input[:, :self.n_qubits]
        quantum_features = self.quantum_circuit(quantum_input)
        
        # ç‰¹å¾´çµåˆ
        combined = torch.cat([conv_features, quantum_features], dim=1)
        
        # äºˆæ¸¬
        piece_type_logits = self.piece_type_head(combined)
        confidence = torch.sigmoid(self.confidence_head(combined))
        
        return piece_type_logits, confidence

class AccurateModelReconstructor:
    """æ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.device = torch.device('cpu')
        
    def reconstruct_exact_model(self, checkpoint_path: str) -> Dict[str, Any]:
        """å®Œå…¨ã«æ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«å†æ§‹æˆ"""
        print(f"ğŸ¯ å®Œå…¨ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆ: {checkpoint_path}")
        print("-" * 50)
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‚’åˆ†æ
            estimator_dict = checkpoint.get('estimator_state', {})
            param_shapes = {name: list(param.shape) for name, param in estimator_dict.items()}
            
            print(f"  ğŸ“Š ç™ºè¦‹ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
            for name, shape in param_shapes.items():
                print(f"    - {name}: {shape}")
            
            # å‹•çš„ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            estimator = DynamicCQCNNEstimator(param_shapes)
            target = DynamicCQCNNEstimator(param_shapes)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            try:
                estimator.load_state_dict(estimator_dict, strict=True)
                print("  âœ… æ¨å®šå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Œå…¨èª­ã¿è¾¼ã¿æˆåŠŸ")
            except Exception as e:
                print(f"  âŒ æ¨å®šå™¨èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                return {'success': False, 'error': str(e)}
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
            try:
                target_dict = checkpoint.get('target_state', {})
                target.load_state_dict(target_dict, strict=True)
                print("  âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®Œå…¨èª­ã¿è¾¼ã¿æˆåŠŸ")
            except Exception as e:
                print(f"  âš ï¸ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­ã¿è¾¼ã¿å¤±æ•—ã€æ¨å®šå™¨ã§ä»£ç”¨: {e}")
                target.load_state_dict(estimator.state_dict())
            
            # å­¦ç¿’çŠ¶æ…‹
            epsilon = checkpoint.get('epsilon', 0.1)
            episodes = checkpoint.get('episodes', 0)
            training_history = checkpoint.get('training_history', {})
            
            reconstructed = {
                'success': True,
                'estimator': estimator,
                'target': target,
                'epsilon': epsilon,
                'episodes': episodes,
                'training_history': training_history,
                'param_shapes': param_shapes
            }
            
            print(f"  ğŸ‰ å®Œå…¨å†æ§‹æˆæˆåŠŸ!")
            print(f"    - æ¢ç´¢ç‡: {epsilon:.6f}")
            print(f"    - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {episodes}")
            print(f"    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {len(param_shapes)}")
            
            return reconstructed
            
        except Exception as e:
            print(f"  âŒ å†æ§‹æˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}
    
    def comprehensive_test(self, reconstructed: Dict[str, Any]) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ§ª åŒ…æ‹¬çš„AIãƒ†ã‚¹ãƒˆ")
        print("-" * 50)
        
        if not reconstructed.get('success', False):
            return {'tested': False, 'reason': 'reconstruction_failed'}
        
        estimator = reconstructed['estimator']
        target = reconstructed['target']
        
        # è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = {
            'empty_board': torch.zeros(1, 25),
            'random_board': torch.randint(-1, 2, (1, 25)).float(),
            'geister_setup': self.create_geister_board(),
            'batch_test': torch.randn(5, 25)
        }
        
        results = {'tested': True, 'test_results': {}}
        
        for test_name, test_input in test_cases.items():
            print(f"  ğŸ”¬ {test_name}ãƒ†ã‚¹ãƒˆ:")
            
            try:
                estimator.eval()
                with torch.no_grad():
                    piece_logits, confidence = estimator(test_input)
                    
                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã‚‚äºˆæ¸¬
                    target_logits, target_conf = target(test_input)
                
                piece_probs = F.softmax(piece_logits, dim=1)
                
                results['test_results'][test_name] = {
                    'success': True,
                    'input_shape': list(test_input.shape),
                    'piece_logits_shape': list(piece_logits.shape),
                    'confidence_shape': list(confidence.shape),
                    'piece_probs_sample': piece_probs[0].tolist(),
                    'confidence_sample': confidence[0].item(),
                    'networks_similar': torch.allclose(piece_logits, target_logits, atol=1e-3)
                }
                
                print(f"    âœ… æˆåŠŸ")
                print(f"    ğŸ“Š å‡ºåŠ›å½¢çŠ¶: é§’ã‚¿ã‚¤ãƒ—{list(piece_logits.shape)}, ç¢ºä¿¡åº¦{list(confidence.shape)}")
                print(f"    ğŸ¯ ã‚µãƒ³ãƒ—ãƒ«ç¢ºç‡: {piece_probs[0][:3].tolist()}")
                print(f"    ğŸ’¯ ç¢ºä¿¡åº¦: {confidence[0].item():.3f}")
                print(f"    ğŸ”— ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é¡ä¼¼åº¦: {'âœ…' if results['test_results'][test_name]['networks_similar'] else 'âŒ'}")
                
            except Exception as e:
                results['test_results'][test_name] = {'success': False, 'error': str(e)}
                print(f"    âŒ å¤±æ•—: {e}")
        
        return results
    
    def create_geister_board(self) -> torch.Tensor:
        """ã‚¬ã‚¤ã‚¹ã‚¿ãƒ¼é¢¨ãƒœãƒ¼ãƒ‰ç”Ÿæˆ"""
        board = torch.zeros(1, 25)
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aï¼ˆä¸‹ï¼‰
        board[0, [5, 6, 8, 9]] = 1.0
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bï¼ˆä¸Šï¼‰
        board[0, [15, 16, 18, 19]] = -1.0
        
        return board
    
    def demonstrate_rl_functionality(self, reconstructed: Dict[str, Any]) -> None:
        """å¼·åŒ–å­¦ç¿’æ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print(f"\nğŸ® å¼·åŒ–å­¦ç¿’æ©Ÿèƒ½ãƒ‡ãƒ¢")
        print("-" * 50)
        
        if not reconstructed.get('success', False):
            print("âŒ å†æ§‹æˆãŒå¤±æ•—ã—ã¦ã„ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return
        
        estimator = reconstructed['estimator']
        target = reconstructed['target']
        epsilon = reconstructed['epsilon']
        history = reconstructed['training_history']
        
        print(f"  ğŸ¯ ç¾åœ¨ã®å­¦ç¿’çŠ¶æ…‹:")
        print(f"    æ¢ç´¢ç‡ (Îµ): {epsilon:.6f}")
        print(f"    å­¦ç¿’æ¸ˆã¿ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {reconstructed['episodes']}")
        
        # Îµ-greedyæˆ¦ç•¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        test_board = self.create_geister_board()
        
        print(f"\n  ğŸ² Îµ-greedyæˆ¦ç•¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
        estimator.eval()
        
        with torch.no_grad():
            piece_logits, confidence = estimator(test_board)
            piece_probs = F.softmax(piece_logits, dim=1)
            
            # æœ€é©è¡Œå‹•ï¼ˆgreedyï¼‰
            best_action = piece_logits.argmax(dim=1).item()
            
            # ãƒ©ãƒ³ãƒ€ãƒ è¡Œå‹•ã®ç¢ºç‡
            random_prob = epsilon
            greedy_prob = 1 - epsilon
            
            print(f"    ğŸ¯ Greedyè¡Œå‹•: ã‚¯ãƒ©ã‚¹{best_action} (ç¢ºç‡: {greedy_prob:.3f})")
            print(f"    ğŸ° Randomè¡Œå‹•ç¢ºç‡: {random_prob:.3f}")
            print(f"    ğŸ’¯ äºˆæ¸¬ç¢ºä¿¡åº¦: {confidence[0].item():.3f}")
        
        # å­¦ç¿’å±¥æ­´ã®åˆ†æ
        if history:
            print(f"\n  ğŸ“ˆ å­¦ç¿’é€²æ—åˆ†æ:")
            
            if 'rewards' in history and history['rewards']:
                rewards = history['rewards']
                print(f"    å¹³å‡å ±é…¬: {np.mean(rewards):.2f}")
                print(f"    æœ€æ–°10ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¹³å‡: {np.mean(rewards[-10:]):.2f}")
                print(f"    æ”¹å–„å‚¾å‘: {'+æ”¹å–„ä¸­' if np.mean(rewards[-10:]) > np.mean(rewards[:10]) else '=åœæ»ä¸­'}")
            
            if 'losses' in history and history['losses']:
                losses = history['losses']
                print(f"    å¹³å‡æå¤±: {np.mean(losses):.4f}")
                print(f"    æœ€æ–°æå¤±: {losses[-1]:.4f}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¯ æ­£ç¢ºãªå¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 70)
    
    reconstructor = AccurateModelReconstructor()
    
    # å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    rl_model_file = None
    for file in os.listdir('.'):
        if file.startswith('rl_') and file.endswith('.pth'):
            rl_model_file = file
            break
    
    if not rl_model_file:
        print("âŒ å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ¯ å¯¾è±¡ãƒ¢ãƒ‡ãƒ«: {rl_model_file}")
    
    # è©³ç´°æ§‹é€ åˆ†æ
    structure = analyze_checkpoint_structure(rl_model_file)
    print(f"\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ§‹é€ æ¦‚è¦:")
    if 'estimator' in structure:
        print(f"  æ¨å®šå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {len(structure['estimator'])}")
        total_params = sum(info['size'] for info in structure['estimator'].values())
        print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
    
    # å®Œå…¨å†æ§‹æˆ
    reconstructed = reconstructor.reconstruct_exact_model(rl_model_file)
    
    if not reconstructed.get('success', False):
        print(f"\nâŒ å†æ§‹æˆå¤±æ•—: {reconstructed.get('error', 'ä¸æ˜')}")
        return
    
    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
    test_results = reconstructor.comprehensive_test(reconstructed)
    
    # å¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¢
    reconstructor.demonstrate_rl_functionality(reconstructed)
    
    print(f"\nğŸ‰ æ¤œè¨¼å®Œäº†ï¼")
    print(f"âœ… å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨å†æ§‹æˆã¨å‹•ä½œç¢ºèªã«æˆåŠŸ")
    
    # æˆåŠŸã—ãŸãƒ†ã‚¹ãƒˆæ•°
    if test_results.get('tested', False):
        successful_tests = sum(1 for result in test_results['test_results'].values() 
                             if result.get('success', False))
        total_tests = len(test_results['test_results'])
        print(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {successful_tests}/{total_tests}")
    
    print(f"\nğŸ” çµè«–:")
    print(f"ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ç¢ºå®Ÿã«å¼·åŒ–å­¦ç¿’ã‚’å®Ÿè£…ã—ã¦ãŠã‚Šã€")
    print(f"ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å®Œå…¨ãªAIå†æ§‹æˆãŒå¯èƒ½ã§ã™ï¼")

if __name__ == "__main__":
    main()