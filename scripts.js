/**
 * Quantum Battle System - JavaScript
 * åˆ†é›¢ã•ã‚ŒãŸJSãƒ•ã‚¡ã‚¤ãƒ« - æ”¹å–„ã—ã‚„ã™ã„æ§‹é€ 
 */

// =================
// ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
// =================
let currentStep = 1;
let selectedMethod = null;
let placedPieces = { good: 0, bad: 0 };
let currentPieceType = 'good';
let boardState = {};
let moduleConfigs = {
    placement: {},
    estimation: {},
    reward: {},
    qmap: {},
    action: {}
};

// =================
// åˆæœŸåŒ–
// =================
document.addEventListener('DOMContentLoaded', function() {
    console.log('ğŸš€ Quantum Battle System åˆæœŸåŒ–é–‹å§‹');
    
    initializeStepNavigation();
    initializePlacementBoard();
    initializeFormElements();
    initializeEventListeners();
    loadSavedConfiguration();
    
    console.log('âœ… åˆæœŸåŒ–å®Œäº†');
});

// =================
// ã‚¹ãƒ†ãƒƒãƒ—ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
// =================
function initializeStepNavigation() {
    const steps = document.querySelectorAll('.step-item');
    steps.forEach((step, index) => {
        step.addEventListener('click', () => goToStep(index + 1));
    });
    
    // æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«
    showStep(currentStep);
}

function goToStep(stepNumber) {
    if (stepNumber < 1 || stepNumber > 5) return;
    
    // ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¿å­˜
    saveCurrentStepData();
    
    // ã‚¹ãƒ†ãƒƒãƒ—ã‚’åˆ‡ã‚Šæ›¿ãˆ
    currentStep = stepNumber;
    showStep(stepNumber);
    
    console.log(`ğŸ“ ã‚¹ãƒ†ãƒƒãƒ— ${stepNumber} ã«ç§»å‹•`);
}

function showStep(stepNumber) {
    // å…¨ã¦ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’éè¡¨ç¤º
    document.querySelectorAll('.step-content').forEach(content => {
        content.classList.remove('active');
    });
    
    // é¸æŠã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º
    const targetContent = document.getElementById(`step${stepNumber}`);
    if (targetContent) {
        targetContent.classList.add('active');
    }
    
    // ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹æ›´æ–°
    updateStepNavigation(stepNumber);
}

function updateStepNavigation(activeStep) {
    const steps = document.querySelectorAll('.step-item');
    const connectors = document.querySelectorAll('.step-connector');
    
    steps.forEach((step, index) => {
        const stepNum = index + 1;
        step.classList.remove('active', 'completed');
        
        if (stepNum === activeStep) {
            step.classList.add('active');
        } else if (stepNum < activeStep) {
            step.classList.add('completed');
        }
    });
    
    connectors.forEach((connector, index) => {
        connector.classList.toggle('completed', index + 1 < activeStep);
    });
}

function nextStep() {
    if (currentStep < 5) {
        goToStep(currentStep + 1);
    }
}

function prevStep() {
    if (currentStep > 1) {
        goToStep(currentStep - 1);
    }
}

// =================
// å­¦ç¿’æ–¹æ³•é¸æŠ (ã‚¹ãƒ†ãƒƒãƒ—1)
// =================
function selectLearningMethod(method) {
    // ä»¥å‰ã®é¸æŠã‚’ã‚¯ãƒªã‚¢
    document.querySelectorAll('.method-card').forEach(card => {
        card.classList.remove('selected');
    });
    
    // æ–°ã—ã„é¸æŠã‚’ãƒãƒ¼ã‚¯
    const selectedCard = document.querySelector(`[onclick="selectLearningMethod('${method}')"]`);
    if (selectedCard) {
        selectedCard.classList.add('selected');
        selectedMethod = method;
        
        console.log(`ğŸ¯ å­¦ç¿’æ–¹æ³•é¸æŠ: ${method}`);
        
        // æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        enableNextStepButton();
    }
}

function enableNextStepButton() {
    const nextButton = document.getElementById('nextStepBtn');
    if (nextButton) {
        nextButton.disabled = false;
        nextButton.classList.remove('btn-disabled');
    }
}

// =================
// é…ç½®ãƒœãƒ¼ãƒ‰ (ã‚¹ãƒ†ãƒƒãƒ—2)
// =================
function initializePlacementBoard() {
    const board = document.getElementById('placementBoard');
    if (!board) return;
    
    board.innerHTML = '';
    
    for (let row = 0; row < 6; row++) {
        for (let col = 0; col < 6; col++) {
            const cell = document.createElement('div');
            cell.className = 'board-cell';
            cell.dataset.row = row;
            cell.dataset.col = col;
            
            // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aé…ç½®ã‚¨ãƒªã‚¢ï¼ˆä¸‹å´2è¡Œã€ä¸­å¤®4åˆ—ï¼‰
            if ((row === 0 || row === 1) && (col >= 1 && col <= 4)) {
                cell.classList.add('player-a-area');
                cell.title = 'ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aé…ç½®ã‚¨ãƒªã‚¢';
                cell.addEventListener('click', () => placePiece(row, col, cell));
            }
            // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bé…ç½®ã‚¨ãƒªã‚¢ï¼ˆä¸Šå´2è¡Œã€ä¸­å¤®4åˆ—ï¼‰
            else if ((row === 4 || row === 5) && (col >= 1 && col <= 4)) {
                cell.classList.add('player-b-area');
                cell.title = 'ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bé…ç½®ã‚¨ãƒªã‚¢';
            }
            
            board.appendChild(cell);
        }
    }
}

function placePiece(row, col, cell) {
    const maxPieces = 4;
    
    if (placedPieces.good >= maxPieces && currentPieceType === 'good') {
        showAlert('å–„ç‰ã¯æœ€å¤§4å€‹ã¾ã§é…ç½®å¯èƒ½ã§ã™', 'warning');
        return;
    }
    
    if (placedPieces.bad >= maxPieces && currentPieceType === 'bad') {
        showAlert('æ‚ªç‰ã¯æœ€å¤§4å€‹ã¾ã§é…ç½®å¯èƒ½ã§ã™', 'warning');
        return;
    }
    
    const key = `${row}-${col}`;
    
    // æ—¢å­˜ã®é§’ã‚’å‰Šé™¤
    if (boardState[key]) {
        placedPieces[boardState[key]]--;
        delete boardState[key];
        cell.classList.remove('placed-good', 'placed-bad');
        cell.textContent = '';
    }
    
    // æ–°ã—ã„é§’ã‚’é…ç½®
    if (currentPieceType === 'good') {
        boardState[key] = 'good';
        placedPieces.good++;
        cell.classList.add('placed-good');
        cell.textContent = 'G';
        currentPieceType = 'bad';
    } else {
        boardState[key] = 'bad';
        placedPieces.bad++;
        cell.classList.add('placed-bad');
        cell.textContent = 'B';
        currentPieceType = 'good';
    }
    
    updatePieceCount();
    checkPlacementCompletion();
}

function updatePieceCount() {
    const goodCount = document.getElementById('goodCount');
    const badCount = document.getElementById('badCount');
    
    if (goodCount) goodCount.textContent = `${placedPieces.good}/4`;
    if (badCount) badCount.textContent = `${placedPieces.bad}/4`;
}

function checkPlacementCompletion() {
    if (placedPieces.good === 4 && placedPieces.bad === 4) {
        showAlert('é…ç½®å®Œäº†ï¼æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚ã¾ã™', 'success');
        enableNextStepButton();
    }
}

function resetPlacement() {
    placedPieces = { good: 0, bad: 0 };
    boardState = {};
    currentPieceType = 'good';
    
    document.querySelectorAll('.board-cell').forEach(cell => {
        cell.classList.remove('placed-good', 'placed-bad');
        cell.textContent = '';
    });
    
    updatePieceCount();
    console.log('ğŸ”„ é…ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ');
}

// =================
// ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ 
// =================
function initializeFormElements() {
    // ãƒ¬ãƒ³ã‚¸ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®å€¤è¡¨ç¤º
    const ranges = document.querySelectorAll('input[type="range"]');
    ranges.forEach(range => {
        const valueDisplay = document.getElementById(range.id + 'Value');
        if (valueDisplay) {
            // åˆæœŸå€¤è¨­å®š
            valueDisplay.textContent = range.value;
            
            // å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ
            range.addEventListener('input', function() {
                valueDisplay.textContent = this.value;
                onParameterChange(this.id, this.value);
            });
        }
    });
    
    // ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®å¤‰æ›´
    const selects = document.querySelectorAll('select');
    selects.forEach(select => {
        select.addEventListener('change', function() {
            onParameterChange(this.id, this.value);
        });
    });
    
    // ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®å¤‰æ›´
    const inputs = document.querySelectorAll('input[type="text"], input[type="number"], textarea');
    inputs.forEach(input => {
        input.addEventListener('input', function() {
            onParameterChange(this.id, this.value);
        });
    });
}

function onParameterChange(parameterId, value) {
    // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ã®ãƒ­ã‚°
    console.log(`ğŸ”§ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´: ${parameterId} = ${value}`);
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°
    updatePreview();
    
    // è‡ªå‹•ä¿å­˜
    autosave();
}

// =================
// ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
// =================
function initializeEventListeners() {
    // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
    document.addEventListener('keydown', function(e) {
        if (e.ctrlKey || e.metaKey) {
            switch(e.key) {
                case 's':
                    e.preventDefault();
                    saveConfiguration();
                    break;
                case 'l':
                    e.preventDefault();
                    loadConfiguration();
                    break;
                case 'g':
                    e.preventDefault();
                    generateAICode();
                    break;
            }
        }
        
        // ã‚¹ãƒ†ãƒƒãƒ—ç§»å‹•ï¼ˆCtrl + æ•°å­—ï¼‰
        if ((e.ctrlKey || e.metaKey) && e.key >= '1' && e.key <= '5') {
            e.preventDefault();
            goToStep(parseInt(e.key));
        }
    });
    
    // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒªã‚µã‚¤ã‚º
    window.addEventListener('resize', debounce(handleResize, 300));
    
    // ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡é˜²æ­¢
    document.addEventListener('submit', function(e) {
        e.preventDefault();
    });
}

function handleResize() {
    // ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–èª¿æ•´
    const isMobile = window.innerWidth < 768;
    document.body.classList.toggle('mobile-view', isMobile);
    
    console.log(`ğŸ“± ç”»é¢ãƒªã‚µã‚¤ã‚º: ${window.innerWidth}px (ãƒ¢ãƒã‚¤ãƒ«: ${isMobile})`);
}

// =================
// AI ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
// =================
function generateAICode() {
    console.log('ğŸ¤– AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆé–‹å§‹');
    
    // è¨­å®šåé›†
    const config = collectAllConfigurations();
    
    // ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    const aiCode = buildAICode(config);
    
    // è¡¨ç¤º
    displayGeneratedCode(aiCode);
    
    console.log('âœ… AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†');
}

function collectAllConfigurations() {
    return {
        learningMethod: selectedMethod,
        placement: {
            strategy: getElementValue('placementStrategy'),
            boardState: boardState,
            placedPieces: placedPieces
        },
        quantum: {
            qubits: parseInt(getElementValue('qubits')),
            layers: parseInt(getElementValue('layers')),
            learningRate: parseFloat(getElementValue('learningRate'))
        },
        rewards: {
            escape: parseInt(getElementValue('escapeReward')),
            capture: parseInt(getElementValue('captureReward')),
            advance: parseInt(getElementValue('advanceReward'))
        },
        action: {
            epsilonStart: parseFloat(getElementValue('epsilonStart')),
            epsilonEnd: parseFloat(getElementValue('epsilonEnd')),
            gamma: parseFloat(getElementValue('gamma'))
        }
    };
}

function buildAICode(config) {
    const timestamp = new Date().toISOString();
    
    return `#!/usr/bin/env python3
"""
Generated Quantum Geister AI
Created: ${timestamp}
Learning Method: ${config.learningMethod}
Auto-generated by Quantum Battle System Designer
"""

import numpy as np
import torch
import torch.nn as nn
import pennylane as qml
from typing import Dict, List, Tuple, Optional
import random

class QuantumGeisterAI:
    """é‡å­å¼·åŒ–å­¦ç¿’ã‚¬ã‚¤ã‚¹ã‚¿ãƒ¼AI"""
    
    def __init__(self):
        # é‡å­ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–
        self.n_qubits = ${config.quantum.qubits}
        self.n_layers = ${config.quantum.layers}
        self.device = qml.device('default.qubit', wires=self.n_qubits)
        
        # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.config = {
            'learning_method': '${config.learningMethod}',
            'placement_strategy': '${config.placement.strategy}',
            'quantum_params': {
                'qubits': ${config.quantum.qubits},
                'layers': ${config.quantum.layers},
                'learning_rate': ${config.quantum.learningRate}
            },
            'reward_params': {
                'escape_reward': ${config.rewards.escape},
                'capture_reward': ${config.rewards.capture},
                'advance_reward': ${config.rewards.advance}
            },
            'rl_params': {
                'epsilon_start': ${config.action.epsilonStart},
                'epsilon_end': ${config.action.epsilonEnd},
                'gamma': ${config.action.gamma}
            }
        }
        
        # å¼·åŒ–å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.epsilon = self.config['rl_params']['epsilon_start']
        self.epsilon_decay = 0.995
        
        # é‡å­å›è·¯ã®é‡ã¿åˆæœŸåŒ–
        self.weights = np.random.random((self.n_layers, self.n_qubits, 2)) * 0.1
        
        print(f"ğŸ§  QuantumGeisterAI åˆæœŸåŒ–å®Œäº†")
        print(f"   é‡å­ãƒ“ãƒƒãƒˆ: {self.n_qubits}")
        print(f"   å›è·¯å±¤æ•°: {self.n_layers}")
        print(f"   å­¦ç¿’æ–¹æ³•: {config.learningMethod}")
    
    @property 
    def quantum_circuit(self):
        """é‡å­å›è·¯å®šç¾©"""
        @qml.qnode(self.device)
        def circuit(inputs, weights):
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å±¤
            for i in range(self.n_qubits):
                qml.RY(inputs[i % len(inputs)], wires=i)
            
            # å¤‰åˆ†å±¤
            for layer in range(self.n_layers):
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–å›è»¢ã‚²ãƒ¼ãƒˆ
                for i in range(self.n_qubits):
                    qml.RY(weights[layer, i, 0], wires=i)
                    qml.RZ(weights[layer, i, 1], wires=i)
                
                # ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆ
                for i in range(self.n_qubits - 1):
                    qml.CNOT(wires=[i, i + 1])
                if self.n_qubits > 2:
                    qml.CNOT(wires=[self.n_qubits - 1, 0])
            
            # æ¸¬å®š
            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]
        
        return circuit
    
    def get_initial_placement(self) -> Dict[Tuple[int, int], str]:
        """åˆæœŸé…ç½®æˆ¦ç•¥"""
        placement = {}
        strategy = self.config['placement_strategy']
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aé…ç½®å¯èƒ½ä½ç½®
        positions = [(0,1), (0,2), (0,3), (0,4), (1,1), (1,2), (1,3), (1,4)]
        
        if strategy == 'aggressive':
            # æ”»æ’ƒçš„: å–„ç‰ã‚’å‰æ–¹ã«
            good_pos = positions[:4]
            bad_pos = positions[4:]
        elif strategy == 'defensive':
            # å®ˆå‚™çš„: å–„ç‰ã‚’å¾Œæ–¹ã«
            good_pos = positions[4:]
            bad_pos = positions[:4]
        else:
            # ãƒãƒ©ãƒ³ã‚¹: äº¤äº’é…ç½®
            good_pos = [positions[0], positions[2], positions[5], positions[7]]
            bad_pos = [positions[1], positions[3], positions[4], positions[6]]
        
        # é…ç½®è¨­å®š
        for pos in good_pos:
            placement[pos] = 'good'
        for pos in bad_pos:
            placement[pos] = 'bad'
        
        return placement
    
    def estimate_enemy_pieces(self, board_state: np.ndarray) -> Dict:
        """æ•µé§’æ¨å®šï¼ˆé‡å­æ©Ÿæ¢°å­¦ç¿’ï¼‰"""
        # ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’é‡å­å›è·¯å…¥åŠ›ã«å¤‰æ›
        board_flat = board_state.flatten()
        inputs = np.pad(board_flat, (0, max(0, self.n_qubits - len(board_flat))))[:self.n_qubits]
        
        # é‡å­å›è·¯ã§æ¨è«–
        quantum_output = self.quantum_circuit(inputs, self.weights)
        
        # ç¢ºç‡åˆ†å¸ƒè¨ˆç®—
        probabilities = torch.softmax(torch.tensor(quantum_output), dim=0).numpy()
        
        return {
            'good_probability': float(probabilities[0]),
            'bad_probability': float(probabilities[1]),
            'confidence': float(np.max(probabilities)),
            'quantum_features': quantum_output
        }
    
    def calculate_reward(self, game_state: Dict, action: Tuple, result: Dict) -> float:
        """å ±é…¬è¨ˆç®—"""
        reward = 0.0
        
        # å‹åˆ©æ¡ä»¶å ±é…¬
        if result.get('is_escape'):
            reward += self.config['reward_params']['escape_reward']
        if result.get('captured_all_good'):
            reward += self.config['reward_params']['capture_reward']
        
        # æˆ¦è¡“è¡Œå‹•å ±é…¬
        if result.get('piece_advanced'):
            reward += self.config['reward_params']['advance_reward']
        if result.get('enemy_piece_captured'):
            reward += 20  # åŸºæœ¬æ•ç²å ±é…¬
        
        # ãƒšãƒŠãƒ«ãƒ†ã‚£
        if result.get('good_piece_lost'):
            reward -= 50
        if result.get('dangerous_move'):
            reward -= 10
        
        return reward
    
    def select_action(self, game_state: Dict, legal_moves: List[Tuple]) -> Tuple:
        """è¡Œå‹•é¸æŠï¼ˆÎµ-greedy + é‡å­æ¨è«–ï¼‰"""
        if len(legal_moves) == 0:
            return None
        
        # Îµ-greedyæˆ¦ç•¥
        if random.random() < self.epsilon:
            # æ¢ç´¢: ãƒ©ãƒ³ãƒ€ãƒ è¡Œå‹•
            action = random.choice(legal_moves)
            print(f"ğŸ² æ¢ç´¢è¡Œå‹•: {action}")
        else:
            # æ´»ç”¨: é‡å­å›è·¯ã«ã‚ˆã‚‹æœ€é©è¡Œå‹•é¸æŠ
            action = self._select_best_action(game_state, legal_moves)
            print(f"ğŸ§  æ´»ç”¨è¡Œå‹•: {action}")
        
        # æ¢ç´¢ç‡æ¸›è¡°
        self.epsilon = max(
            self.config['rl_params']['epsilon_end'],
            self.epsilon * self.epsilon_decay
        )
        
        return action
    
    def _select_best_action(self, game_state: Dict, legal_moves: List[Tuple]) -> Tuple:
        """é‡å­å›è·¯ã«ã‚ˆã‚‹æœ€é©è¡Œå‹•é¸æŠ"""
        best_action = None
        best_score = float('-inf')
        
        board_state = game_state.get('board', np.zeros((6, 6)))
        
        for move in legal_moves:
            # è¡Œå‹•è©•ä¾¡
            score = self._evaluate_action(board_state, move)
            
            if score > best_score:
                best_score = score
                best_action = move
        
        return best_action or legal_moves[0]
    
    def _evaluate_action(self, board_state: np.ndarray, action: Tuple) -> float:
        """è¡Œå‹•è©•ä¾¡"""
        from_pos, to_pos = action
        
        # åŸºæœ¬ã‚¹ã‚³ã‚¢
        score = 0.0
        
        # å‰é€²è©•ä¾¡
        if to_pos[0] > from_pos[0]:  # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®å ´åˆã€Yåº§æ¨™ãŒå¢—åŠ 
            score += 5.0
        
        # è„±å‡ºè©•ä¾¡
        if to_pos in [(0, 5), (5, 5)]:  # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®è„±å‡ºå£
            score += 50.0
        
        # å®‰å…¨æ€§è©•ä¾¡
        if 1 <= to_pos[0] <= 4 and 1 <= to_pos[1] <= 4:  # ä¸­å¤®ã¯å±é™º
            score -= 5.0
        
        # é‡å­å›è·¯ã«ã‚ˆã‚‹è©³ç´°è©•ä¾¡
        try:
            board_input = board_state.flatten()
            inputs = np.pad(board_input, (0, max(0, self.n_qubits - len(board_input))))[:self.n_qubits]
            quantum_score = np.sum(self.quantum_circuit(inputs, self.weights))
            score += quantum_score * 0.1
        except Exception as e:
            print(f"âš ï¸ é‡å­è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        
        return score
    
    def update_weights(self, experience: Dict):
        """é‡ã¿æ›´æ–°ï¼ˆå­¦ç¿’ï¼‰"""
        # ç°¡æ˜“çš„ãªé‡ã¿æ›´æ–°
        learning_rate = self.config['quantum_params']['learning_rate']
        
        # å ±é…¬ã«åŸºã¥ãé‡ã¿èª¿æ•´
        reward = experience.get('reward', 0)
        if reward > 0:
            self.weights += learning_rate * np.random.random(self.weights.shape) * 0.01
        else:
            self.weights -= learning_rate * np.random.random(self.weights.shape) * 0.01
        
        # é‡ã¿ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        self.weights = np.clip(self.weights, -np.pi, np.pi)
    
    def save_model(self, filepath: str):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        model_data = {
            'weights': self.weights.tolist(),
            'config': self.config,
            'epsilon': self.epsilon
        }
        
        import json
        with open(filepath, 'w') as f:
            json.dump(model_data, f, indent=2)
        
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {filepath}")
    
    def load_model(self, filepath: str):
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        import json
        with open(filepath, 'r') as f:
            model_data = json.load(f)
        
        self.weights = np.array(model_data['weights'])
        self.config.update(model_data['config'])
        self.epsilon = model_data['epsilon']
        
        print(f"ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {filepath}")

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # AIåˆæœŸåŒ–
    ai = QuantumGeisterAI()
    
    # åˆæœŸé…ç½®ãƒ†ã‚¹ãƒˆ
    placement = ai.get_initial_placement()
    print(f"åˆæœŸé…ç½®: {placement}")
    
    # ãƒ†ã‚¹ãƒˆãƒœãƒ¼ãƒ‰çŠ¶æ…‹
    test_board = np.random.randint(-1, 2, (6, 6))
    
    # æ•µé§’æ¨å®šãƒ†ã‚¹ãƒˆ
    estimation = ai.estimate_enemy_pieces(test_board)
    print(f"æ•µé§’æ¨å®š: {estimation}")
    
    # è¡Œå‹•é¸æŠãƒ†ã‚¹ãƒˆ
    legal_moves = [((0, 1), (0, 2)), ((1, 1), (1, 2))]
    game_state = {'board': test_board}
    action = ai.select_action(game_state, legal_moves)
    print(f"é¸æŠè¡Œå‹•: {action}")
    
    print("ğŸ‰ é‡å­ã‚¬ã‚¤ã‚¹ã‚¿ãƒ¼AI ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
`;
}

function displayGeneratedCode(code) {
    const codeOutput = document.getElementById('codeOutput');
    if (codeOutput) {
        codeOutput.textContent = code;
        
        // ã‚³ãƒ¼ãƒ‰è¡¨ç¤ºã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
        const codeContainer = document.getElementById('generatedCode');
        if (codeContainer) {
            codeContainer.style.display = 'block';
        }
    }
    
    showAlert('AIã‚³ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼', 'success');
}

// =================
// è¨­å®šä¿å­˜ãƒ»èª­ã¿è¾¼ã¿
// =================
function saveConfiguration() {
    const config = collectAllConfigurations();
    
    try {
        localStorage.setItem('quantum_battle_config', JSON.stringify(config));
        showAlert('è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ', 'success');
        console.log('ğŸ’¾ è¨­å®šä¿å­˜å®Œäº†');
    } catch (error) {
        showAlert('è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ', 'error');
        console.error('âŒ è¨­å®šä¿å­˜ã‚¨ãƒ©ãƒ¼:', error);
    }
}

function loadSavedConfiguration() {
    try {
        const saved = localStorage.getItem('quantum_battle_config');
        if (saved) {
            const config = JSON.parse(saved);
            applyConfiguration(config);
            console.log('ğŸ“‚ ä¿å­˜è¨­å®šã‚’èª­ã¿è¾¼ã¿');
        }
    } catch (error) {
        console.error('âš ï¸ è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
    }
}

function loadConfiguration() {
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = '.json';
    
    input.onchange = function(event) {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = function(e) {
                try {
                    const config = JSON.parse(e.target.result);
                    applyConfiguration(config);
                    showAlert('è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ', 'success');
                } catch (error) {
                    showAlert('è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ', 'error');
                }
            };
            reader.readAsText(file);
        }
    };
    
    input.click();
}

function applyConfiguration(config) {
    // å­¦ç¿’æ–¹æ³•
    if (config.learningMethod) {
        selectedMethod = config.learningMethod;
    }
    
    // é…ç½®è¨­å®š
    if (config.placement) {
        if (config.placement.boardState) {
            boardState = config.placement.boardState;
        }
        if (config.placement.placedPieces) {
            placedPieces = config.placement.placedPieces;
        }
    }
    
    // ãƒ•ã‚©ãƒ¼ãƒ å€¤ã®å¾©å…ƒ
    Object.keys(config).forEach(section => {
        if (typeof config[section] === 'object') {
            Object.keys(config[section]).forEach(key => {
                const element = document.getElementById(key);
                if (element) {
                    element.value = config[section][key];
                    // å€¤è¡¨ç¤ºã®æ›´æ–°
                    const valueDisplay = document.getElementById(key + 'Value');
                    if (valueDisplay) {
                        valueDisplay.textContent = config[section][key];
                    }
                }
            });
        }
    });
    
    // ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã®å¾©å…ƒ
    updatePlacementBoardFromState();
    updatePieceCount();
}

function updatePlacementBoardFromState() {
    document.querySelectorAll('.board-cell').forEach(cell => {
        const row = parseInt(cell.dataset.row);
        const col = parseInt(cell.dataset.col);
        const key = `${row}-${col}`;
        
        cell.classList.remove('placed-good', 'placed-bad');
        cell.textContent = '';
        
        if (boardState[key]) {
            if (boardState[key] === 'good') {
                cell.classList.add('placed-good');
                cell.textContent = 'G';
            } else {
                cell.classList.add('placed-bad');
                cell.textContent = 'B';
            }
        }
    });
}

// =================
// ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
// =================
function getElementValue(id) {
    const element = document.getElementById(id);
    return element ? element.value : '';
}

function showAlert(message, type = 'info') {
    // æ—¢å­˜ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å‰Šé™¤
    const existingAlert = document.querySelector('.alert-temporary');
    if (existingAlert) {
        existingAlert.remove();
    }
    
    // æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆ
    const alert = document.createElement('div');
    alert.className = `alert alert-${type} alert-temporary`;
    alert.textContent = message;
    
    // ãƒšãƒ¼ã‚¸ã®ä¸Šéƒ¨ã«è¿½åŠ 
    const container = document.querySelector('.container');
    container.insertBefore(alert, container.firstChild);
    
    // 3ç§’å¾Œã«è‡ªå‹•å‰Šé™¤
    setTimeout(() => {
        if (alert.parentNode) {
            alert.remove();
        }
    }, 3000);
}

function debounce(func, delay) {
    let timeoutId;
    return function (...args) {
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => func.apply(this, args), delay);
    };
}

function saveCurrentStepData() {
    // ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    moduleConfigs[`step${currentStep}`] = collectCurrentStepData();
}

function collectCurrentStepData() {
    const stepData = {};
    
    // ç¾åœ¨è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã‹ã‚‰å€¤ã‚’åé›†
    const activeContent = document.querySelector('.step-content.active');
    if (activeContent) {
        const inputs = activeContent.querySelectorAll('input, select, textarea');
        inputs.forEach(input => {
            if (input.id) {
                stepData[input.id] = input.value;
            }
        });
    }
    
    return stepData;
}

function updatePreview() {
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®ã§500mså¾Œã«å®Ÿè¡Œ
    clearTimeout(updatePreview.timeoutId);
    updatePreview.timeoutId = setTimeout(() => {
        // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯
        console.log('ğŸ”„ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°');
    }, 500);
}

function autosave() {
    // è‡ªå‹•ä¿å­˜ï¼ˆ2ç§’å¾Œï¼‰
    clearTimeout(autosave.timeoutId);
    autosave.timeoutId = setTimeout(() => {
        saveConfiguration();
    }, 2000);
}

// ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
function downloadCode() {
    const code = document.getElementById('codeOutput')?.textContent;
    if (!code) {
        showAlert('ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“', 'warning');
        return;
    }
    
    const blob = new Blob([code], { type: 'text/python' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `quantum_geister_ai_${Date.now()}.py`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    
    showAlert('ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ', 'success');
}

function copyToClipboard() {
    const code = document.getElementById('codeOutput')?.textContent;
    if (!code) {
        showAlert('ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“', 'warning');
        return;
    }
    
    navigator.clipboard.writeText(code).then(() => {
        showAlert('ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ', 'success');
    }).catch(() => {
        showAlert('ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã¸ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ', 'error');
    });
}

// ãƒ‡ãƒãƒƒã‚°ç”¨
window.QuantumBattleDebug = {
    getCurrentStep: () => currentStep,
    getSelectedMethod: () => selectedMethod,
    getBoardState: () => boardState,
    getPlacedPieces: () => placedPieces,
    getModuleConfigs: () => moduleConfigs,
    collectAllConfigurations: collectAllConfigurations
};