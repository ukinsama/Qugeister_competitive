#!/usr/bin/env python3
"""
æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼
ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å®Œå…¨ãªAIã‚’å†æ§‹æˆ
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import os

class ImprovedModelLoader:
    """æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    def __init__(self):
        self.device = torch.device('cpu')
        
    def analyze_checkpoint_detailed(self, checkpoint_path: str) -> Dict[str, Any]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°åˆ†æ"""
        print(f"\nğŸ” è©³ç´°åˆ†æ: {checkpoint_path}")
        print("-" * 50)
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        analysis = {
            'file_size': os.path.getsize(checkpoint_path),
            'structure': {},
            'model_info': {},
            'training_info': {},
            'reconstruction_strategy': 'unknown'
        }
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ§‹é€ ã®è©³ç´°åˆ†æ
        for key, value in checkpoint.items():
            print(f"ğŸ“‹ {key}:")
            
            if key == 'estimator_state' and isinstance(value, dict):
                analysis['model_info']['estimator_params'] = len(value)
                print(f"  ğŸ§  æ¨å®šå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {len(value)} å€‹")
                for param_name, param_tensor in list(value.items())[:3]:
                    print(f"    - {param_name}: {list(param_tensor.shape)}")
                if len(value) > 3:
                    print(f"    ... ä»– {len(value) - 3} å€‹")
                    
            elif key == 'target_state' and isinstance(value, dict):
                analysis['model_info']['target_params'] = len(value)
                print(f"  ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {len(value)} å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                
            elif key == 'model_state_dict' and isinstance(value, dict):
                analysis['model_info']['main_model_params'] = len(value)
                total_params = sum(v.numel() for v in value.values())
                print(f"  ğŸ—ï¸ ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {len(value)} ãƒ¬ã‚¤ãƒ¤ãƒ¼, {total_params:,} ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                
            elif key == 'optimizer_state' or key == 'optimizer_state_dict':
                print(f"  âš™ï¸ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹: ä¿å­˜æ¸ˆã¿")
                analysis['training_info']['has_optimizer'] = True
                
            elif key == 'epsilon' and isinstance(value, (int, float)):
                print(f"  ğŸ² æ¢ç´¢ç‡: {value:.6f}")
                analysis['training_info']['epsilon'] = value
                
            elif key == 'episodes' and isinstance(value, int):
                print(f"  ğŸ“ˆ å­¦ç¿’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {value}")
                analysis['training_info']['episodes'] = value
                
            elif key == 'training_history' and isinstance(value, dict):
                print(f"  ğŸ“Š å­¦ç¿’å±¥æ­´:")
                for hist_key, hist_value in value.items():
                    if isinstance(hist_value, list):
                        print(f"    - {hist_key}: {len(hist_value)} è¨˜éŒ²")
                        if hist_value:  # ç©ºã§ãªã„å ´åˆ
                            if isinstance(hist_value[0], (int, float)):
                                print(f"      åˆæœŸå€¤: {hist_value[0]:.6f}, æœ€çµ‚å€¤: {hist_value[-1]:.6f}")
                analysis['training_info']['history'] = value
                
            elif key == 'history' and isinstance(value, dict):
                print(f"  ğŸ“œ å­¦ç¿’è¨˜éŒ²:")
                for hist_key, hist_value in value.items():
                    if isinstance(hist_value, list):
                        print(f"    - {hist_key}: {len(hist_value)} ã‚¨ãƒ³ãƒˆãƒª")
                        
        # å†æ§‹æˆæˆ¦ç•¥ã®æ±ºå®š
        if 'estimator_state' in checkpoint and 'target_state' in checkpoint:
            analysis['reconstruction_strategy'] = 'rl_cqcnn'
            print(f"\nğŸ¯ å†æ§‹æˆæˆ¦ç•¥: å¼·åŒ–å­¦ç¿’CQCNN (DQNã‚¹ã‚¿ã‚¤ãƒ«)")
        elif 'model_state_dict' in checkpoint:
            analysis['reconstruction_strategy'] = 'standard_model'
            print(f"\nğŸ—ï¸ å†æ§‹æˆæˆ¦ç•¥: æ¨™æº–ãƒ¢ãƒ‡ãƒ«")
        else:
            analysis['reconstruction_strategy'] = 'unknown'
            print(f"\nâ“ å†æ§‹æˆæˆ¦ç•¥: ä¸æ˜")
            
        return analysis
    
    def create_minimal_cqcnn(self, param_shapes: Dict[str, List[int]]) -> nn.Module:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‹ã‚‰æœ€å°é™ã®CQCNNã‚’ä½œæˆ"""
        
        class MinimalCQCNN(nn.Module):
            def __init__(self, param_info):
                super().__init__()
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢çŠ¶ã‹ã‚‰æ¨å®šã—ã¦ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æ§‹ç¯‰
                self.layers = nn.ModuleDict()
                
                for name, shape in param_info.items():
                    if 'weight' in name and len(shape) == 2:
                        # ç·šå½¢ãƒ¬ã‚¤ãƒ¤ãƒ¼
                        layer_name = name.replace('.weight', '')
                        self.layers[layer_name] = nn.Linear(shape[1], shape[0])
                    elif 'conv' in name.lower() and len(shape) == 4:
                        # ç•³ã¿è¾¼ã¿ãƒ¬ã‚¤ãƒ¤ãƒ¼
                        layer_name = name.replace('.weight', '')
                        self.layers[layer_name] = nn.Conv2d(shape[1], shape[0], 
                                                          kernel_size=shape[2:])
                        
            def forward(self, x):
                # ç°¡å˜ãªé †ä¼æ’­ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯é©åˆ‡ã«å®Ÿè£…ï¼‰
                for layer in self.layers.values():
                    if isinstance(layer, nn.Linear):
                        x = x.view(x.size(0), -1)  # Flatten
                        x = layer(x)
                    elif isinstance(layer, nn.Conv2d):
                        x = layer(x)
                return x
                
        return MinimalCQCNN(param_shapes)
    
    def attempt_full_reconstruction(self, checkpoint_path: str) -> Optional[Dict[str, Any]]:
        """å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚’è©¦è¡Œ"""
        print(f"\nğŸ”§ å®Œå…¨å†æ§‹æˆè©¦è¡Œ: {checkpoint_path}")
        print("-" * 50)
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            analysis = self.analyze_checkpoint_detailed(checkpoint_path)
            
            reconstructed = {
                'success': False,
                'models': {},
                'optimizers': {},
                'training_state': {},
                'errors': []
            }
            
            if analysis['reconstruction_strategy'] == 'rl_cqcnn':
                print("ğŸ¯ å¼·åŒ–å­¦ç¿’CQCNNå†æ§‹æˆã‚’è©¦è¡Œ...")
                
                # æ¨å®šå™¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†æ§‹æˆ
                if 'estimator_state' in checkpoint:
                    estimator_dict = checkpoint['estimator_state']
                    param_shapes = {k: list(v.shape) for k, v in estimator_dict.items()}
                    
                    try:
                        estimator = self.create_minimal_cqcnn(param_shapes)
                        estimator.load_state_dict(estimator_dict)
                        reconstructed['models']['estimator'] = estimator
                        print("  âœ… æ¨å®šå™¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†æ§‹æˆæˆåŠŸ")
                    except Exception as e:
                        reconstructed['errors'].append(f"æ¨å®šå™¨å†æ§‹æˆå¤±æ•—: {e}")
                        print(f"  âŒ æ¨å®šå™¨å†æ§‹æˆå¤±æ•—: {e}")
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†æ§‹æˆ
                if 'target_state' in checkpoint:
                    target_dict = checkpoint['target_state']
                    param_shapes = {k: list(v.shape) for k, v in target_dict.items()}
                    
                    try:
                        target = self.create_minimal_cqcnn(param_shapes)
                        target.load_state_dict(target_dict)
                        reconstructed['models']['target'] = target
                        print("  âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†æ§‹æˆæˆåŠŸ")
                    except Exception as e:
                        reconstructed['errors'].append(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå†æ§‹æˆå¤±æ•—: {e}")
                        print(f"  âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå†æ§‹æˆå¤±æ•—: {e}")
                
                # å­¦ç¿’çŠ¶æ…‹ã®å¾©å…ƒ
                if 'epsilon' in checkpoint:
                    reconstructed['training_state']['epsilon'] = checkpoint['epsilon']
                    print(f"  âœ… æ¢ç´¢ç‡å¾©å…ƒ: {checkpoint['epsilon']:.6f}")
                    
                if 'episodes' in checkpoint:
                    reconstructed['training_state']['episodes'] = checkpoint['episodes']
                    print(f"  âœ… ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°å¾©å…ƒ: {checkpoint['episodes']}")
                    
                if 'training_history' in checkpoint:
                    reconstructed['training_state']['history'] = checkpoint['training_history']
                    history = checkpoint['training_history']
                    if 'rewards' in history and history['rewards']:
                        recent_reward = history['rewards'][-1] if history['rewards'] else 0
                        print(f"  âœ… å­¦ç¿’å±¥æ­´å¾©å…ƒ: æœ€æ–°å ±é…¬ {recent_reward:.3f}")
                        
            elif analysis['reconstruction_strategy'] == 'standard_model':
                print("ğŸ—ï¸ æ¨™æº–ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚’è©¦è¡Œ...")
                
                if 'model_state_dict' in checkpoint:
                    model_dict = checkpoint['model_state_dict']
                    param_shapes = {k: list(v.shape) for k, v in model_dict.items()}
                    
                    try:
                        model = self.create_minimal_cqcnn(param_shapes)
                        model.load_state_dict(model_dict)
                        reconstructed['models']['main'] = model
                        print("  âœ… ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆæˆåŠŸ")
                    except Exception as e:
                        reconstructed['errors'].append(f"ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆå¤±æ•—: {e}")
                        print(f"  âŒ ãƒ¢ãƒ‡ãƒ«å†æ§‹æˆå¤±æ•—: {e}")
            
            # æˆåŠŸåˆ¤å®š
            reconstructed['success'] = len(reconstructed['models']) > 0
            
            if reconstructed['success']:
                print(f"ğŸ‰ å†æ§‹æˆæˆåŠŸ! {len(reconstructed['models'])} å€‹ã®ãƒ¢ãƒ‡ãƒ«å¾©å…ƒ")
            else:
                print("âŒ å†æ§‹æˆå¤±æ•—")
                
            return reconstructed
            
        except Exception as e:
            print(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def test_reconstructed_models(self, reconstructed: Dict[str, Any]) -> Dict[str, Any]:
        """å†æ§‹æˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ§ª å†æ§‹æˆãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
        print("-" * 50)
        
        if not reconstructed.get('success', False):
            print("âŒ å†æ§‹æˆãŒå¤±æ•—ã—ã¦ã„ã‚‹ãŸã‚ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return {'tested': False, 'reason': 'reconstruction_failed'}
        
        test_results = {'tested': True, 'model_tests': {}}
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        test_input = torch.randn(1, 25)  # 5x5ã®ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã•ã‚ŒãŸå…¥åŠ›
        
        for model_name, model in reconstructed['models'].items():
            print(f"ğŸ”¬ {model_name}ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ:")
            
            try:
                model.eval()
                with torch.no_grad():
                    output = model(test_input)
                    
                test_results['model_tests'][model_name] = {
                    'success': True,
                    'input_shape': list(test_input.shape),
                    'output_shape': list(output.shape),
                    'output_mean': output.mean().item(),
                    'output_std': output.std().item(),
                    'output_range': [output.min().item(), output.max().item()]
                }
                
                print(f"  âœ… æ¨è«–æˆåŠŸ")
                print(f"  ğŸ“Š å‡ºåŠ›å½¢çŠ¶: {list(output.shape)}")
                print(f"  ğŸ“ˆ å‡ºåŠ›çµ±è¨ˆ: å¹³å‡={output.mean().item():.4f}, æ¨™æº–åå·®={output.std().item():.4f}")
                
            except Exception as e:
                test_results['model_tests'][model_name] = {
                    'success': False,
                    'error': str(e)
                }
                print(f"  âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        
        return test_results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”§ æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«å†æ§‹æˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 70)
    
    loader = ImprovedModelLoader()
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
    model_files = [f for f in os.listdir('.') if f.endswith('.pth')]
    
    if not model_files:
        print("âŒ .pthãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“ ç™ºè¦‹ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {len(model_files)} å€‹")
    
    for model_file in model_files:
        print(f"\n" + "="*70)
        print(f"ğŸ¯ å‡¦ç†ä¸­: {model_file}")
        
        # è©³ç´°åˆ†æ
        analysis = loader.analyze_checkpoint_detailed(model_file)
        
        # å®Œå…¨å†æ§‹æˆè©¦è¡Œ
        reconstructed = loader.attempt_full_reconstruction(model_file)
        
        # å†æ§‹æˆãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
        if reconstructed:
            test_results = loader.test_reconstructed_models(reconstructed)
        
    print(f"\nğŸ‰ æ¤œè¨¼å®Œäº†!")
    print("çµè«–: ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰éƒ¨åˆ†çš„ãªå†æ§‹æˆãŒå¯èƒ½ã§ã™ã€‚")
    print("å®Œå…¨ãªå®Ÿç”¨åŒ–ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«æ§‹é€ æƒ…å ±ã®æ˜ç¤ºçš„ãªä¿å­˜ãŒå¿…è¦ã§ã™ã€‚")

if __name__ == "__main__":
    main()