# AI Maker System

**cqcnn_battle_learning_systemã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸAIåˆ¶ä½œã‚·ã‚¹ãƒ†ãƒ **

## ğŸ¯ æ¦‚è¦

AI Maker Systemã¯ã€`cqcnn_battle_learning_system.py`ã®æ©Ÿèƒ½ã‚’5ã¤ã®ç‹¬ç«‹ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†é›¢ã—ã€çµ„ã¿åˆã‚ã›è‡ªç”±ãªAIåˆ¶ä½œã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦å†æ§‹ç¯‰ã—ãŸã‚‚ã®ã§ã™ã€‚

## ğŸ“ ã‚·ã‚¹ãƒ†ãƒ æ§‹é€ 

```
ai_maker_system/
â”œâ”€â”€ __init__.py                 # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åˆæœŸåŒ–
â”œâ”€â”€ core/                       # ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_modules.py         # æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ãƒ»CQCNNãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ data_processor.py       # 7ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿å‡¦ç†
â”‚   â””â”€â”€ game_state.py           # ã‚²ãƒ¼ãƒ çŠ¶æ…‹ãƒ»è¨­å®šç®¡ç†
â”œâ”€â”€ modules/                    # 5ã¤ã®æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ placement.py            # åˆæœŸé…ç½®æˆ¦ç•¥
â”‚   â”œâ”€â”€ estimator.py            # æ•µé§’æ¨å®šå™¨ï¼ˆCQCNNå­¦ç¿’ä»˜ãï¼‰
â”‚   â”œâ”€â”€ reward.py               # å ±é…¬é–¢æ•°
â”‚   â”œâ”€â”€ qmap.py                 # Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆå™¨
â”‚   â””â”€â”€ action.py               # è¡Œå‹•é¸æŠå™¨
â”œâ”€â”€ learning/                   # å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ supervised.py           # æ•™å¸«ã‚ã‚Šå­¦ç¿’
â”‚   â””â”€â”€ reinforcement.py        # å¼·åŒ–å­¦ç¿’ï¼ˆDQNï¼‰
â”œâ”€â”€ ai_builder.py               # AIãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼‰
â””â”€â”€ README.md                   # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
from ai_maker_system import AIBuilder

# AIãƒ“ãƒ«ãƒ€ãƒ¼åˆæœŸåŒ–
builder = AIBuilder(output_dir="my_ais")

# AIè¨­å®šã‚’å®šç¾©
config = {
    'name': 'MyQuantumAI',
    'placement': {'type': 'aggressive'},
    'estimator': {'type': 'cqcnn', 'n_qubits': 6, 'n_layers': 3},
    'reward': {'type': 'aggressive'},
    'qmap': {'type': 'strategic', 'strategy': 'aggressive'},
    'action': {'type': 'epsilon_greedy', 'epsilon': 0.1},
    'model': {'n_qubits': 6, 'n_layers': 3},
    'learning': {'type': 'reinforcement', 'episodes': 500},
    'auto_train': True
}

# AIä½œæˆ
ai_info = builder.create_ai(config)
print(f"AIä½œæˆå®Œäº†: {ai_info['name']}")
```

### ãƒ‡ãƒ¢å®Ÿè¡Œ

```bash
cd Qugeister_competitive
python ai_maker_demo.py
```

## ğŸ“¦ 5ã¤ã®æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### 1. é…ç½®æˆ¦ç•¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (placement.py)
- `StandardPlacement`: æ¨™æº–çš„ãªé…ç½®
- `AggressivePlacement`: æ”»æ’ƒçš„é…ç½®ï¼ˆå–„ç‰ã‚’å‰ç·šã«ï¼‰
- `DefensivePlacement`: é˜²å¾¡çš„é…ç½®ï¼ˆå–„ç‰ã‚’å¾Œæ–¹ã«ï¼‰
- `CustomPlacement`: ã‚«ã‚¹ã‚¿ãƒ é…ç½®

### 2. æ¨å®šå™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (estimator.py)
- `CQCNNEstimator`: CQCNNå­¦ç¿’æ©Ÿèƒ½ä»˜ãæ¨å®šå™¨
- `SimpleEstimator`: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ©ãƒ³ãƒ€ãƒ æ¨å®šå™¨

### 3. å ±é…¬é–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (reward.py)
- `BasicReward`: åŸºæœ¬çš„ãªå ±é…¬é–¢æ•°
- `AggressiveReward`: æ”»æ’ƒçš„å ±é…¬é–¢æ•°
- `DefensiveReward`: é˜²å¾¡çš„å ±é…¬é–¢æ•°
- `EscapeReward`: è„±å‡ºé‡è¦–å ±é…¬é–¢æ•°

### 4. Qå€¤ãƒãƒƒãƒ—ç”Ÿæˆå™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (qmap.py)
- `SimpleQMapGenerator`: ã‚·ãƒ³ãƒ—ãƒ«ãªQå€¤ãƒãƒƒãƒ—
- `StrategicQMapGenerator`: æˆ¦ç•¥çš„Qå€¤ãƒãƒƒãƒ—
- `LearnedQMapGenerator`: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹

### 5. è¡Œå‹•é¸æŠå™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (action.py)
- `GreedySelector`: è²ªæ¬²é¸æŠ
- `EpsilonGreedySelector`: Îµ-è²ªæ¬²é¸æŠ
- `BoltzmannSelector`: ãƒœãƒ«ãƒ„ãƒãƒ³é¸æŠ
- `UCBSelector`: UCBé¸æŠ
- `RandomSelector`: ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ

## ğŸ“ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

### æ•™å¸«ã‚ã‚Šå­¦ç¿’ (supervised.py)
- CQCNNãƒ¢ãƒ‡ãƒ«ã®æ•™å¸«ã‚ã‚Šå­¦ç¿’
- ãƒãƒƒãƒå­¦ç¿’ãƒ»æ¤œè¨¼ãƒ»Early Stopping
- å­¦ç¿’å±¥æ­´ã®è¨˜éŒ²

### å¼·åŒ–å­¦ç¿’ (reinforcement.py)  
- DQNï¼ˆDeep Q-Networkï¼‰å®Ÿè£…
- çµŒé¨“ãƒªãƒ—ãƒ¬ã‚¤ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
- Îµ-greedyæ¢ç´¢

## ğŸ—ï¸ AIãƒ“ãƒ«ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 

`AIBuilder`ã‚¯ãƒ©ã‚¹ãŒå…¨ä½“ã‚’çµ±åˆã—ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›:

- **AIä½œæˆ**: è¨­å®šã«åŸºã¥ã„ã¦AIç”Ÿæˆ
- **è‡ªå‹•å­¦ç¿’**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å­¦ç¿’ã‚‚å®Ÿè¡Œ
- **è‡ªå‹•ä¿å­˜**: ãƒ¢ãƒ‡ãƒ«ãƒ»è¨­å®šãƒ»å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿å­˜
- **3stepäº’æ›**: æ—¢å­˜ã®3stepã‚·ã‚¹ãƒ†ãƒ ã¨ã®äº’æ›æ€§

## ğŸ’¾ å‡ºåŠ›å½¢å¼

å„AIã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™:

```
generated_ais/MyQuantumAI/
â”œâ”€â”€ ai_info.json              # AIè©³ç´°æƒ…å ±
â”œâ”€â”€ model.pth                 # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ modules.json              # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š
â””â”€â”€ MyQuantumAI_ai.py         # å®Ÿè¡Œå¯èƒ½ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¿½åŠ 

1. é©åˆ‡ãªæŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿
2. `process()`, `get_name()`, `get_config()` ã‚’å®Ÿè£…
3. ãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚¯ãƒ©ã‚¹ã«è¿½åŠ 

ä¾‹:
```python
class MyCustomReward(RewardFunction):
    def calculate_reward(self, state_before, action, state_after, player):
        # ã‚«ã‚¹ã‚¿ãƒ å ±é…¬ãƒ­ã‚¸ãƒƒã‚¯
        return reward_value
    
    def get_name(self):
        return "My Custom Reward"
    
    def get_config(self):
        return {"type": "custom", "param": "value"}
```

## ğŸ¯ 3stepã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ

3stepã‚·ã‚¹ãƒ†ãƒ ã§ç”Ÿæˆã•ã‚ŒãŸè¨­å®šã‹ã‚‰ç›´æ¥AIã‚’ä½œæˆå¯èƒ½:

```python
# 3stepã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š
step3_config = {
    'reward': 'aggressive',
    'qubits': 8,
    'layers': 3,
    'placement': 'aggressive',
    'learningMethod': 'reinforcement'
}

# AIä½œæˆ
ai = builder.create_ai_from_3step_config(step3_config)
```

## ğŸ”¬ ç‰¹å¾´

- **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–**: æ©Ÿèƒ½ã”ã¨ã«ç‹¬ç«‹ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- **æ‹¡å¼µæ€§**: æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç°¡å˜ã«è¿½åŠ å¯èƒ½
- **å†åˆ©ç”¨æ€§**: æ—¢å­˜ã®cqcnnã‚³ãƒ¼ãƒ‰ã‚’85%å†åˆ©ç”¨
- **äº’æ›æ€§**: 3stepã‚·ã‚¹ãƒ†ãƒ ã¨ã®å®Œå…¨äº’æ›
- **è‡ªå‹•åŒ–**: å­¦ç¿’ã‹ã‚‰ãƒ‡ãƒ—ãƒ­ã‚¤ã¾ã§è‡ªå‹•åŒ–

## ğŸ“Š åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³

```python
# å…¨ã¦ã®åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
builder = AIBuilder()
modules = builder.list_available_modules()
print(modules)
# {
#   'placement': ['standard', 'aggressive', 'defensive', 'custom'],
#   'estimator': ['cqcnn', 'simple'], 
#   'reward': ['basic', 'aggressive', 'defensive', 'escape'],
#   'qmap': ['simple', 'strategic', 'learned'],
#   'action': ['greedy', 'epsilon_greedy', 'boltzmann', 'ucb', 'random']
# }
```

## ğŸ‰ ã¾ã¨ã‚

AI Maker Systemã«ã‚ˆã‚Šã€cqcnn_battle_learning_systemã®è¤‡é›‘ãªæ©Ÿèƒ½ã‚’ç°¡å˜ã«çµ„ã¿åˆã‚ã›ã¦AIã‚’ä½œæˆã§ãã¾ã™ã€‚3stepã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºã«ã‚ˆã‚Šã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨­å®šã‹ã‚‰ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€å­¦ç¿’ã€å®Ÿè¡Œã¾ã§ä¸€è²«ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚