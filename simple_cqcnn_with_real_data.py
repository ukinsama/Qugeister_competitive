#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«CQCNNå®Ÿè£… - å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ç‰ˆ
å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ãƒ—ãƒ¬ã‚¤ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦å­¦ç¿’
"""

import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple, Optional
import random
import time

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src', 'qugeister_competitive')
sys.path.insert(0, src_path)
sys.path.insert(0, current_dir)

# ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã‚’èª­ã¿è¾¼ã¿
print("ğŸ“‚ ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿ä¸­...")
try:
    with open(os.path.join(src_path, 'game_engine.py'), 'r') as f:
        game_engine_code = f.read()
    exec(game_engine_code)
    
    with open(os.path.join(src_path, 'ai_base.py'), 'r') as f:
        ai_base_code = f.read().replace('from .game_engine', '# from .game_engine')
    exec(ai_base_code)
    print("âœ… ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿å®Œäº†")
except Exception as e:
    print(f"âš ï¸ ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    print("ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")


# ================================================================================
# Part 1: ã‚·ãƒ³ãƒ—ãƒ«ãªCNNãƒ¢ãƒ‡ãƒ«ï¼ˆå‰å›ã¨åŒã˜ï¼‰
# ================================================================================

class SimpleCQCNN(nn.Module):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªCNNé§’æ¨å®šãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self):
        super().__init__()
        
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2),  # 6x6 -> 3x3
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Flatten()
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(64 * 3 * 3, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 2)  # 2ã‚¯ãƒ©ã‚¹: good(0) or bad(1)
        )
    
    def forward(self, x):
        features = self.feature_extractor(x)
        output = self.classifier(features)
        return output


# ================================================================================
# Part 2: å®Ÿã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
# ================================================================================

class RealGameDataGenerator:
    """å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ãƒ—ãƒ¬ã‚¤ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    
    @staticmethod
    def generate_game_data(num_games: int = 100) -> List[Dict]:
        """å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
        print(f"ğŸ® {num_games}ã‚²ãƒ¼ãƒ ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        all_data = []
        
        for game_idx in range(num_games):
            game = GeisterGame()
            player_a = RandomAI("A")
            player_b = RandomAI("B")
            
            # ã‚²ãƒ¼ãƒ é€²è¡Œ
            turn_count = 0
            max_turns = 50
            
            while not game.game_over and turn_count < max_turns:
                current_player = player_a if game.current_player == "A" else player_b
                legal_moves = game.get_legal_moves(game.current_player)
                
                if not legal_moves:
                    break
                
                # ã‚¿ãƒ¼ãƒ³5ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆåºç›¤ã¯é™¤å¤–ï¼‰
                if turn_count >= 5:
                    # ç¾åœ¨ã®ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’è¨˜éŒ²
                    board_state = game.board.copy()
                    
                    # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®è¦–ç‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                    if random.random() < 0.5:
                        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã®é§’ï¼ˆæ•µé§’ï¼‰ã®ä½ç½®ã¨ç¨®é¡ã‚’è¨˜éŒ²
                        for pos, piece_type in game.player_b_pieces.items():
                            if board_state[pos[1], pos[0]] == -1:  # æ•µé§’ã®ç¢ºèª
                                data = {
                                    'board': board_state.copy(),
                                    'player': 'A',
                                    'enemy_pos': pos,
                                    'enemy_type': piece_type,  # 'good' or 'bad'
                                    'turn': turn_count
                                }
                                all_data.append(data)
                    else:
                        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã®è¦–ç‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                        for pos, piece_type in game.player_a_pieces.items():
                            if board_state[pos[1], pos[0]] == 1:  # æ•µé§’ã®ç¢ºèª
                                data = {
                                    'board': board_state.copy(),
                                    'player': 'B',
                                    'enemy_pos': pos,
                                    'enemy_type': piece_type,  # 'good' or 'bad'
                                    'turn': turn_count
                                }
                                all_data.append(data)
                
                # æ‰‹ã‚’å®Ÿè¡Œ
                move = current_player.get_move(
                    game.get_game_state(game.current_player), 
                    legal_moves
                )
                if move:
                    game.make_move(move[0], move[1])
                
                turn_count += 1
            
            if (game_idx + 1) % 20 == 0:
                print(f"  {game_idx + 1}/{num_games} ã‚²ãƒ¼ãƒ å®Œäº†")
        
        print(f"âœ… {len(all_data)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ç”Ÿæˆ")
        return all_data
    
    @staticmethod
    def prepare_batch(data_list: List[Dict], batch_size: int = 32):
        """ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‹ã‚‰ãƒãƒƒãƒã‚’ä½œæˆ"""
        if len(data_list) < batch_size:
            batch_size = len(data_list)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        batch_data = random.sample(data_list, batch_size)
        
        batch_inputs = []
        batch_labels = []
        
        for data in batch_data:
            # ãƒœãƒ¼ãƒ‰ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            tensor = RealGameDataGenerator.board_to_tensor(
                data['board'], 
                data['player']
            )
            
            # ãƒ©ãƒ™ãƒ«ï¼ˆ0: good, 1: badï¼‰
            label = 0 if data['enemy_type'] == 'good' else 1
            
            batch_inputs.append(tensor)
            batch_labels.append(label)
        
        return torch.stack(batch_inputs), torch.tensor(batch_labels, dtype=torch.long)
    
    @staticmethod
    def board_to_tensor(board: np.ndarray, player: str) -> torch.Tensor:
        """ãƒœãƒ¼ãƒ‰ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›"""
        tensor = torch.zeros(3, 6, 6, dtype=torch.float32)
        
        player_val = 1 if player == 'A' else -1
        enemy_val = -player_val
        
        tensor[0] = torch.from_numpy((board == player_val).astype(np.float32))
        tensor[1] = torch.from_numpy((board == enemy_val).astype(np.float32))
        tensor[2] = torch.from_numpy((board == 0).astype(np.float32))
        
        return tensor


# ================================================================================
# Part 3: æ”¹è‰¯ç‰ˆãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
# ================================================================================

class ImprovedTrainer:
    """å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, model, learning_rate=0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        self.history = {
            'loss': [],
            'accuracy': [],
            'val_accuracy': []
        }
    
    def train_with_real_data(self, train_data: List[Dict], 
                            val_data: Optional[List[Dict]] = None,
                            epochs: int = 50, 
                            batch_size: int = 32):
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’"""
        print(f"\nğŸ“ å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’é–‹å§‹")
        print(f"   å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_data)}")
        if val_data:
            print(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ•°: {len(val_data)}")
        print("=" * 60)
        
        for epoch in range(epochs):
            # å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º
            self.model.train()
            epoch_losses = []
            epoch_correct = 0
            epoch_total = 0
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            random.shuffle(train_data)
            
            # ãƒãƒƒãƒã”ã¨ã«å­¦ç¿’
            num_batches = len(train_data) // batch_size
            for batch_idx in range(num_batches):
                start_idx = batch_idx * batch_size
                end_idx = start_idx + batch_size
                batch_data = train_data[start_idx:end_idx]
                
                # ãƒãƒƒãƒæº–å‚™
                inputs, labels = RealGameDataGenerator.prepare_batch(batch_data, batch_size)
                
                # é †ä¼æ’­
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                
                # é€†ä¼æ’­
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                # çµ±è¨ˆè¨˜éŒ²
                epoch_losses.append(loss.item())
                _, predicted = torch.max(outputs.data, 1)
                epoch_correct += (predicted == labels).sum().item()
                epoch_total += labels.size(0)
            
            # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆ
            avg_loss = np.mean(epoch_losses) if epoch_losses else 0
            train_accuracy = epoch_correct / epoch_total if epoch_total > 0 else 0
            
            self.history['loss'].append(avg_loss)
            self.history['accuracy'].append(train_accuracy)
            
            # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º
            val_accuracy = 0
            if val_data:
                val_accuracy = self.evaluate(val_data, batch_size)
                self.history['val_accuracy'].append(val_accuracy)
            
            # é€²æ—è¡¨ç¤º
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1:3d}/{epochs} | "
                      f"Loss: {avg_loss:.4f} | "
                      f"Train Acc: {train_accuracy:.3f}", end="")
                if val_data:
                    print(f" | Val Acc: {val_accuracy:.3f}")
                else:
                    print()
        
        print("\nâœ… å­¦ç¿’å®Œäº†ï¼")
        self.plot_history()
    
    def evaluate(self, data: List[Dict], batch_size: int = 32) -> float:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            num_batches = len(data) // batch_size
            for batch_idx in range(num_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(data))
                batch_data = data[start_idx:end_idx]
                
                if not batch_data:
                    continue
                
                inputs, labels = RealGameDataGenerator.prepare_batch(batch_data, len(batch_data))
                outputs = self.model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        return correct / total if total > 0 else 0
    
    def plot_history(self):
        """å­¦ç¿’å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        if not self.history['loss']:
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))
        
        # æå¤±
        axes[0].plot(self.history['loss'], 'b-', label='Training Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].set_title('Training Loss')
        axes[0].grid(True)
        axes[0].legend()
        
        # ç²¾åº¦
        axes[1].plot(self.history['accuracy'], 'g-', label='Training Accuracy')
        if self.history['val_accuracy']:
            axes[1].plot(self.history['val_accuracy'], 'r-', label='Validation Accuracy')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Accuracy')
        axes[1].set_title('Model Accuracy')
        axes[1].grid(True)
        axes[1].legend()
        
        plt.tight_layout()
        plt.savefig('real_data_training.png')
        print("ğŸ“Š å­¦ç¿’æ›²ç·šã‚’ä¿å­˜: real_data_training.png")


# ================================================================================
# Part 4: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ================================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ã‚·ãƒ³ãƒ—ãƒ«CQCNN - å®Ÿã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ç‰ˆ")
    print("=" * 70)
    
    # 1. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    print("\n[Step 1] ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
    print("-" * 40)
    model = SimpleCQCNN()
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")
    print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("\n[Step 2] å®Ÿã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    print("-" * 40)
    
    # ã‚²ãƒ¼ãƒ ãƒ—ãƒ¬ã‚¤ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    all_data = RealGameDataGenerator.generate_game_data(num_games=100)
    
    # å­¦ç¿’ç”¨ã¨æ¤œè¨¼ç”¨ã«åˆ†å‰²ï¼ˆ8:2ï¼‰
    random.shuffle(all_data)
    split_idx = int(len(all_data) * 0.8)
    train_data = all_data[:split_idx]
    val_data = all_data[split_idx:]
    
    print(f"   å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_data)}å€‹")
    print(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_data)}å€‹")
    
    # 3. å­¦ç¿’å®Ÿè¡Œ
    print("\n[Step 3] å­¦ç¿’å®Ÿè¡Œ")
    print("-" * 40)
    trainer = ImprovedTrainer(model, learning_rate=0.001)
    trainer.train_with_real_data(
        train_data, 
        val_data,
        epochs=50,
        batch_size=32
    )
    
    # 4. æœ€çµ‚è©•ä¾¡
    print("\n[Step 4] æœ€çµ‚è©•ä¾¡")
    print("-" * 40)
    
    final_train_acc = trainer.evaluate(train_data, batch_size=32)
    final_val_acc = trainer.evaluate(val_data, batch_size=32)
    
    print(f"æœ€çµ‚å­¦ç¿’ç²¾åº¦: {final_train_acc:.1%}")
    print(f"æœ€çµ‚æ¤œè¨¼ç²¾åº¦: {final_val_acc:.1%}")
    
    # 5. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    print("\n[Step 5] ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
    print("-" * 40)
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': trainer.optimizer.state_dict(),
        'history': trainer.history,
        'final_train_acc': final_train_acc,
        'final_val_acc': final_val_acc
    }, 'real_data_model.pth')
    print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: real_data_model.pth")
    
    # 6. ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ğŸ“Š å®Ÿé¨“ã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    
    print(f"ãƒ‡ãƒ¼ã‚¿ç·æ•°: {len(all_data)}å€‹")
    print(f"æœ€çµ‚å­¦ç¿’ç²¾åº¦: {final_train_acc:.1%}")
    print(f"æœ€çµ‚æ¤œè¨¼ç²¾åº¦: {final_val_acc:.1%}")
    
    # æˆåŠŸåˆ¤å®š
    if final_val_acc > 0.55:
        print("\nâœ… å­¦ç¿’æˆåŠŸï¼")
        print("   ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ãƒ³ãƒ€ãƒ ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚")
        print("   æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: é‡å­å›è·¯ã‚’è¿½åŠ ã—ã¦ã•ã‚‰ã«æ€§èƒ½å‘ä¸Š")
    elif final_val_acc > 0.52:
        print("\nâš ï¸  éƒ¨åˆ†çš„ãªå­¦ç¿’æˆåŠŸ")
        print("   ã‚ãšã‹ã«ãƒ©ãƒ³ãƒ€ãƒ ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚")
        print("   ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    else:
        print("\nâŒ å­¦ç¿’ãŒä¸ååˆ†")
        print("   ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚")
    
    print("\nğŸ‰ å®Ÿé¨“å®Œäº†ï¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ å®Ÿè¡Œä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
