#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«CQCNNå®Ÿè£… - å‹•ä½œç¢ºèªç‰ˆ
é‡å­å›è·¯ãªã—ã€åŸºæœ¬çš„ãªCNNã§é§’æ¨å®šã‚’å­¦ç¿’
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple
import random
import time

# ================================================================================
# Part 1: ã‚·ãƒ³ãƒ—ãƒ«ãªCNNãƒ¢ãƒ‡ãƒ«
# ================================================================================

class SimpleCQCNN(nn.Module):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªCNNé§’æ¨å®šãƒ¢ãƒ‡ãƒ«ï¼ˆé‡å­å›è·¯ãªã—ï¼‰"""
    
    def __init__(self):
        super().__init__()
        
        # CNNç‰¹å¾´æŠ½å‡ºå™¨
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2),  # 6x6 -> 3x3
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Flatten()
        )
        
        # åˆ†é¡ãƒ˜ãƒƒãƒ‰
        self.classifier = nn.Sequential(
            nn.Linear(64 * 3 * 3, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 2)  # 2ã‚¯ãƒ©ã‚¹: good(0) or bad(1)
        )
    
    def forward(self, x):
        """é †ä¼æ’­"""
        features = self.feature_extractor(x)
        output = self.classifier(features)
        return output


# ================================================================================
# Part 2: ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
# ================================================================================

class SimpleDataGenerator:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_random_board():
        """ãƒ©ãƒ³ãƒ€ãƒ ãªãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ç”Ÿæˆ"""
        board = np.zeros((6, 6), dtype=np.float32)
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®é§’ã‚’é…ç½®ï¼ˆ1ï½4å€‹ï¼‰
        num_a = random.randint(1, 4)
        positions_a = random.sample([(i, j) for i in range(6) for j in range(6)], num_a)
        for pos in positions_a:
            board[pos[0], pos[1]] = 1
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã®é§’ã‚’é…ç½®ï¼ˆ1ï½4å€‹ï¼‰
        available_positions = [(i, j) for i in range(6) for j in range(6) 
                              if board[i, j] == 0]
        num_b = min(random.randint(1, 4), len(available_positions))
        positions_b = random.sample(available_positions, num_b)
        for pos in positions_b:
            board[pos[0], pos[1]] = -1
        
        return board, positions_a, positions_b
    
    @staticmethod
    def board_to_tensor(board, player='A'):
        """ãƒœãƒ¼ãƒ‰ã‚’3ãƒãƒ£ãƒ³ãƒãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›"""
        tensor = torch.zeros(3, 6, 6, dtype=torch.float32)
        
        player_val = 1 if player == 'A' else -1
        enemy_val = -player_val
        
        # ãƒãƒ£ãƒ³ãƒãƒ«0: è‡ªé§’
        tensor[0] = torch.from_numpy((board == player_val).astype(np.float32))
        # ãƒãƒ£ãƒ³ãƒãƒ«1: æ•µé§’
        tensor[1] = torch.from_numpy((board == enemy_val).astype(np.float32))
        # ãƒãƒ£ãƒ³ãƒãƒ«2: ç©ºãƒã‚¹
        tensor[2] = torch.from_numpy((board == 0).astype(np.float32))
        
        return tensor
    
    @staticmethod
    def generate_batch(batch_size=32):
        """ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        batch_inputs = []
        batch_labels = []
        
        for _ in range(batch_size):
            board, pos_a, pos_b = SimpleDataGenerator.generate_random_board()
            
            # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã‹ã‚‰è¦‹ãŸå ´åˆ
            if random.random() < 0.5:
                tensor = SimpleDataGenerator.board_to_tensor(board, 'A')
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã®é§’ï¼ˆæ•µé§’ï¼‰ã®ãƒ©ãƒ™ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š
                label = random.randint(0, 1)  # 0: good, 1: bad
            else:
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Bã‹ã‚‰è¦‹ãŸå ´åˆ
                tensor = SimpleDataGenerator.board_to_tensor(board, 'B')
                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼Aã®é§’ï¼ˆæ•µé§’ï¼‰ã®ãƒ©ãƒ™ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š
                label = random.randint(0, 1)
            
            batch_inputs.append(tensor)
            batch_labels.append(label)
        
        return torch.stack(batch_inputs), torch.tensor(batch_labels, dtype=torch.long)


# ================================================================================
# Part 3: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
# ================================================================================

class SimpleTrainer:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªå­¦ç¿’ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, learning_rate=0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        self.history = {
            'loss': [],
            'accuracy': []
        }
    
    def train_epoch(self, num_batches=10, batch_size=32):
        """1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’"""
        epoch_losses = []
        epoch_correct = 0
        epoch_total = 0
        
        self.model.train()
        
        for _ in range(num_batches):
            # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            inputs, labels = SimpleDataGenerator.generate_batch(batch_size)
            
            # é †ä¼æ’­
            outputs = self.model(inputs)
            loss = self.criterion(outputs, labels)
            
            # é€†ä¼æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # çµ±è¨ˆè¨˜éŒ²
            epoch_losses.append(loss.item())
            _, predicted = torch.max(outputs.data, 1)
            epoch_correct += (predicted == labels).sum().item()
            epoch_total += labels.size(0)
        
        avg_loss = np.mean(epoch_losses)
        accuracy = epoch_correct / epoch_total
        
        self.history['loss'].append(avg_loss)
        self.history['accuracy'].append(accuracy)
        
        return avg_loss, accuracy
    
    def train(self, epochs=50, num_batches=10, batch_size=32):
        """å­¦ç¿’å®Ÿè¡Œ"""
        print("ğŸ“ å­¦ç¿’é–‹å§‹")
        print("=" * 60)
        
        for epoch in range(epochs):
            loss, accuracy = self.train_epoch(num_batches, batch_size)
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1:3d}/{epochs} | "
                      f"Loss: {loss:.4f} | "
                      f"Accuracy: {accuracy:.3f}")
        
        print("\nâœ… å­¦ç¿’å®Œäº†ï¼")
        self.plot_history()
    
    def plot_history(self):
        """å­¦ç¿’å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        if not self.history['loss']:
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # æå¤±
        ax1.plot(self.history['loss'], 'b-')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training Loss')
        ax1.grid(True)
        
        # ç²¾åº¦
        ax2.plot(self.history['accuracy'], 'g-')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Training Accuracy')
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig('simple_cqcnn_training.png')
        print("ğŸ“Š å­¦ç¿’æ›²ç·šã‚’ä¿å­˜: simple_cqcnn_training.png")


# ================================================================================
# Part 4: ãƒ†ã‚¹ãƒˆã¨è©•ä¾¡
# ================================================================================

class SimpleEvaluator:
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def test_model(model, num_tests=100):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for _ in range(num_tests):
                inputs, labels = SimpleDataGenerator.generate_batch(1)
                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = correct / total
        return accuracy
    
    @staticmethod
    def inference_speed_test(model, num_iterations=100):
        """æ¨è«–é€Ÿåº¦ã‚’ãƒ†ã‚¹ãƒˆ"""
        model.eval()
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        dummy_input = torch.randn(1, 3, 6, 6)
        for _ in range(10):
            _ = model(dummy_input)
        
        # é€Ÿåº¦æ¸¬å®š
        start_time = time.time()
        with torch.no_grad():
            for _ in range(num_iterations):
                inputs, _ = SimpleDataGenerator.generate_batch(1)
                _ = model(inputs)
        
        elapsed_time = time.time() - start_time
        avg_time = elapsed_time / num_iterations * 1000  # ãƒŸãƒªç§’
        
        return avg_time


# ================================================================================
# Part 5: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ================================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ã‚·ãƒ³ãƒ—ãƒ«CQCNNå‹•ä½œç¢ºèª")
    print("=" * 70)
    
    # 1. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    print("\n[Step 1] ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
    print("-" * 40)
    model = SimpleCQCNN()
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")
    print(f"   ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
    print(f"   å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
    
    # 2. å­¦ç¿’
    print("\n[Step 2] å­¦ç¿’å®Ÿè¡Œ")
    print("-" * 40)
    trainer = SimpleTrainer(model, learning_rate=0.001)
    trainer.train(epochs=30, num_batches=20, batch_size=32)
    
    # 3. è©•ä¾¡
    print("\n[Step 3] ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
    print("-" * 40)
    
    # ç²¾åº¦ãƒ†ã‚¹ãƒˆ
    test_accuracy = SimpleEvaluator.test_model(model, num_tests=200)
    print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1%}")
    
    # é€Ÿåº¦ãƒ†ã‚¹ãƒˆ
    avg_inference_time = SimpleEvaluator.inference_speed_test(model, num_iterations=100)
    print(f"å¹³å‡æ¨è«–æ™‚é–“: {avg_inference_time:.2f}ms")
    
    # 4. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    print("\n[Step 4] ãƒ¢ãƒ‡ãƒ«ä¿å­˜")
    print("-" * 40)
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': trainer.optimizer.state_dict(),
        'history': trainer.history
    }, 'simple_cqcnn_checkpoint.pth')
    print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: simple_cqcnn_checkpoint.pth")
    
    # 5. ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ğŸ“Š å®Ÿé¨“ã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    
    final_loss = trainer.history['loss'][-1] if trainer.history['loss'] else 0
    final_accuracy = trainer.history['accuracy'][-1] if trainer.history['accuracy'] else 0
    
    print(f"æœ€çµ‚æå¤±: {final_loss:.4f}")
    print(f"æœ€çµ‚å­¦ç¿’ç²¾åº¦: {final_accuracy:.1%}")
    print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1%}")
    print(f"æ¨è«–é€Ÿåº¦: {avg_inference_time:.2f}ms/sample")
    
    # æœŸå¾…å€¤ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰ã¯50%ãªã®ã§ã€ãã‚Œã‚’è¶…ãˆã¦ã„ã‚Œã°å­¦ç¿’æˆåŠŸ
    if final_accuracy > 0.55:
        print("\nâœ… å­¦ç¿’æˆåŠŸï¼ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ãƒ³ãƒ€ãƒ ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚")
        print("   æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’")
    else:
        print("\nâš ï¸  å­¦ç¿’ãŒä¸ååˆ†ã§ã™ã€‚")
        print("   ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
    
    print("\nğŸ‰ å‹•ä½œç¢ºèªå®Œäº†ï¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ å®Ÿè¡Œä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
